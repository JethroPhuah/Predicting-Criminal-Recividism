{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "%matplotlib inline \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from urllib.request import urlopen \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import OrderedDict  \n",
    "data_path = r\"C:\\Users\\jethr\\ICPSR_36404-V2\\ICPSR_36404\\DS0001\\36404-0001-Data.tsv\"\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/deep-learning-python#preprocess\n",
    "\n",
    "https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "https://stackoverflow.com/questions/43798377/one-hot-encode-categorical-variables-and-scale-continuous-ones-simultaneouely\n",
    "\n",
    "https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(filename):\n",
    "    df = pd.read_csv(data_path, header=0, sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID        object\n",
      "SEX                   int64\n",
      "ADMTYPE               int64\n",
      "OFFGENERAL            int64\n",
      "EDUCATION             int64\n",
      "ADMITYR               int64\n",
      "RELEASEYR             int64\n",
      "MAND_PRISREL_YEAR    object\n",
      "PROJ_PRISREL_YEAR    object\n",
      "PARELIG_YEAR         object\n",
      "SENTLGTH             object\n",
      "OFFDETAIL             int64\n",
      "RACE                  int64\n",
      "AGEADMIT              int64\n",
      "AGERELEASE           object\n",
      "TIMESRVD              int64\n",
      "RELTYPE              object\n",
      "STATE                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = build_df(data_path)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\" \", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A012015000000091071</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A022015000000096906</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A042015000000118649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A062015000000167469</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A132015000000550479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1968</td>\n",
       "      <td>1972</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "0  A012015000000091071    1        1           2          9     2006   \n",
       "1  A022015000000096906    1        3           3          9     2008   \n",
       "2  A042015000000118649    1        1           1          9     2013   \n",
       "3  A062015000000167469    1        2           2          9     1996   \n",
       "4  A132015000000550479    1        1           1          9     1968   \n",
       "\n",
       "   RELEASEYR MAND_PRISREL_YEAR PROJ_PRISREL_YEAR PARELIG_YEAR SENTLGTH  \\\n",
       "0       2010               NaN               NaN          NaN        4   \n",
       "1       2008               NaN               NaN          NaN        0   \n",
       "2       2014              2014              2014          NaN        0   \n",
       "3       1996               NaN               NaN          NaN        2   \n",
       "4       1972              1978               NaN          NaN        3   \n",
       "\n",
       "   OFFDETAIL  RACE  AGEADMIT AGERELEASE  TIMESRVD RELTYPE  STATE  \n",
       "0         10     9         3          3         2       3      1  \n",
       "1         12     1         3          3         0     NaN      2  \n",
       "2          6     1         1          1         0       1      4  \n",
       "3          7     1         2          2         0       1      6  \n",
       "4          4     1         1          1         2       1     13  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.convert_objects(convert_numeric=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type :  <class 'pandas.core.frame.DataFrame'>\n",
      "Data dims :  (10907333, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type : \", type(df))\n",
    "print(\"Data dims : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID              0\n",
      "SEX                        0\n",
      "ADMTYPE                    0\n",
      "OFFGENERAL                 0\n",
      "EDUCATION                  0\n",
      "ADMITYR                    0\n",
      "RELEASEYR                  0\n",
      "MAND_PRISREL_YEAR    7209317\n",
      "PROJ_PRISREL_YEAR    4662333\n",
      "PARELIG_YEAR         8148769\n",
      "SENTLGTH               20063\n",
      "OFFDETAIL                  0\n",
      "RACE                       0\n",
      "AGEADMIT                   0\n",
      "AGERELEASE           1200886\n",
      "TIMESRVD                   0\n",
      "RELTYPE              1809372\n",
      "STATE                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2d0e0d6b610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "missing_data.plot(kind='bar', color='Red', title=\"Number of Rows Missing Data\", grid=True).legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above graph, most of the missing data are related to the year when the prisoner is going to be released. For example, some columns such as PARELIG_YEAR are missing almost 80% of their values. Therefore, we cannot impute the values in these columns as more data is missing than available. It is best that we drop all missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "6       A182015000000019353    2        3           3          9     2008   \n",
       "23      A442015000000038143    1        1           3          9     2007   \n",
       "287979  A042015000000273326    1        1           2          9     2012   \n",
       "404424  A042015000000190084    1        1           1          9     2012   \n",
       "488157  A042015000000224709    1        2           1          9     2012   \n",
       "\n",
       "        RELEASEYR MAND_PRISREL_YEAR PROJ_PRISREL_YEAR PARELIG_YEAR SENTLGTH  \\\n",
       "6            2009              2010              2009         2009        2   \n",
       "23           2008              2008              2008         2007        1   \n",
       "287979       2013              2013              2013         2013        3   \n",
       "404424       2014              2014              2014         2014        3   \n",
       "488157       2013              2013              2013         2011        4   \n",
       "\n",
       "        OFFDETAIL  RACE  AGEADMIT AGERELEASE  TIMESRVD RELTYPE  STATE  \n",
       "6              12     1         2          2         0       1     18  \n",
       "23             12     2         4          4         1       2     44  \n",
       "287979         10     1         5          5         1       1      4  \n",
       "404424          1     1         4          4         1       1      4  \n",
       "488157          3     1         5          5         0       1      4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert relevant data types from object to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-cf14f2ca324f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['MAND_PRISREL_YEAR'] = complete_rows['MAND_PRISREL_YEAR'].astype(str).astype(int)\n",
      "<ipython-input-11-cf14f2ca324f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['PROJ_PRISREL_YEAR'] = complete_rows['PROJ_PRISREL_YEAR'].astype(str).astype(int)\n",
      "<ipython-input-11-cf14f2ca324f>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['PARELIG_YEAR'] = complete_rows['PARELIG_YEAR'].astype(str).astype(int)\n",
      "<ipython-input-11-cf14f2ca324f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(str).astype(int)\n",
      "<ipython-input-11-cf14f2ca324f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(str).astype(int)\n",
      "<ipython-input-11-cf14f2ca324f>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(str).astype(int)\n"
     ]
    }
   ],
   "source": [
    "complete_rows['MAND_PRISREL_YEAR'] = complete_rows['MAND_PRISREL_YEAR'].astype(str).astype(int)\n",
    "complete_rows['PROJ_PRISREL_YEAR'] = complete_rows['PROJ_PRISREL_YEAR'].astype(str).astype(int)\n",
    "complete_rows['PARELIG_YEAR'] = complete_rows['PARELIG_YEAR'].astype(str).astype(int)\n",
    "complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(str).astype(int)\n",
    "complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(str).astype(int)\n",
    "complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert relevant data types from object to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-30e05d9d4249>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['SEX'] = complete_rows['SEX'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['ADMTYPE'] = complete_rows['ADMTYPE'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['OFFGENERAL'] = complete_rows['OFFGENERAL'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['EDUCATION'] = complete_rows['EDUCATION'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['OFFDETAIL'] = complete_rows['OFFDETAIL'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['RACE'] = complete_rows['RACE'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['AGEADMIT'] = complete_rows['AGEADMIT'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['TIMESRVD'] = complete_rows['TIMESRVD'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(\"category\")\n",
      "<ipython-input-12-30e05d9d4249>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_rows['STATE'] = complete_rows['STATE'].astype(\"category\")\n"
     ]
    }
   ],
   "source": [
    "complete_rows['SEX'] = complete_rows['SEX'].astype(\"category\")\n",
    "complete_rows['ADMTYPE'] = complete_rows['ADMTYPE'].astype(\"category\")\n",
    "complete_rows['OFFGENERAL'] = complete_rows['OFFGENERAL'].astype(\"category\")\n",
    "complete_rows['EDUCATION'] = complete_rows['EDUCATION'].astype(\"category\")\n",
    "complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(\"category\")\n",
    "complete_rows['OFFDETAIL'] = complete_rows['OFFDETAIL'].astype(\"category\")\n",
    "complete_rows['RACE'] = complete_rows['RACE'].astype(\"category\")\n",
    "complete_rows['AGEADMIT'] = complete_rows['AGEADMIT'].astype(\"category\")\n",
    "complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(\"category\")\n",
    "complete_rows['TIMESRVD'] = complete_rows['TIMESRVD'].astype(\"category\")\n",
    "complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(\"category\")\n",
    "complete_rows['STATE'] = complete_rows['STATE'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID          object\n",
      "SEX                  category\n",
      "ADMTYPE              category\n",
      "OFFGENERAL           category\n",
      "EDUCATION            category\n",
      "ADMITYR                 int64\n",
      "RELEASEYR               int64\n",
      "MAND_PRISREL_YEAR       int32\n",
      "PROJ_PRISREL_YEAR       int32\n",
      "PARELIG_YEAR            int32\n",
      "SENTLGTH             category\n",
      "OFFDETAIL            category\n",
      "RACE                 category\n",
      "AGEADMIT             category\n",
      "AGERELEASE           category\n",
      "TIMESRVD             category\n",
      "RELTYPE              category\n",
      "STATE                category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(complete_rows.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720189\n"
     ]
    }
   ],
   "source": [
    "print(len(complete_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, eventhough we have dropped more than 90% of the data, we are still left with 720K rows which is more than enough to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABT_INMATE_ID SEX ADMTYPE OFFGENERAL EDUCATION  ADMITYR  \\\n",
       "6       A182015000000019353   2       3          3         9     2008   \n",
       "23      A442015000000038143   1       1          3         9     2007   \n",
       "287979  A042015000000273326   1       1          2         9     2012   \n",
       "404424  A042015000000190084   1       1          1         9     2012   \n",
       "488157  A042015000000224709   1       2          1         9     2012   \n",
       "\n",
       "        RELEASEYR  MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR  \\\n",
       "6            2009               2010               2009          2009   \n",
       "23           2008               2008               2008          2007   \n",
       "287979       2013               2013               2013          2013   \n",
       "404424       2014               2014               2014          2014   \n",
       "488157       2013               2013               2013          2011   \n",
       "\n",
       "       SENTLGTH OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6             2        12    1        2          2        0       1    18  \n",
       "23            1        12    2        4          4        1       2    44  \n",
       "287979        3        10    1        5          5        1       1     4  \n",
       "404424        3         1    1        4          4        1       1     4  \n",
       "488157        4         3    1        5          5        0       1     4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data file contains one record for each separate term in prison. An individual person may have more than one record, but all will be assigned the same Abt_Inmate_ID value. Thus, we iterate through the dataset to find deuplicate copies of Abt_Inmate_ID value which indicates that the felony has recommited a crime. We will mark 0 as non-repeated offender and 1 as repeated offender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = complete_rows.set_index('ABT_INMATE_ID').index.duplicated(keep=False) #If the index is duplicated, TRUE, else FALSE\n",
    "repeat = repeat * 1 #Change true and false to 1 and 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recividism = [x + 0 for x in repeat] #add 1 to all the numbers in repeat.\n",
    "se = pd.Series(recividism)\n",
    "complete_rows.insert(0, 'recidivism', se.values) #insert this row inside\n",
    "#it will be binary from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recidivism        ABT_INMATE_ID SEX ADMTYPE OFFGENERAL EDUCATION  \\\n",
       "6                1  A182015000000019353   2       3          3         9   \n",
       "23               1  A442015000000038143   1       1          3         9   \n",
       "287979           0  A042015000000273326   1       1          2         9   \n",
       "404424           0  A042015000000190084   1       1          1         9   \n",
       "488157           0  A042015000000224709   1       2          1         9   \n",
       "\n",
       "        ADMITYR  RELEASEYR  MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  \\\n",
       "6          2008       2009               2010               2009   \n",
       "23         2007       2008               2008               2008   \n",
       "287979     2012       2013               2013               2013   \n",
       "404424     2012       2014               2014               2014   \n",
       "488157     2012       2013               2013               2013   \n",
       "\n",
       "        PARELIG_YEAR SENTLGTH OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD  \\\n",
       "6               2009        2        12    1        2          2        0   \n",
       "23              2007        1        12    2        4          4        1   \n",
       "287979          2013        3        10    1        5          5        1   \n",
       "404424          2014        3         1    1        4          4        1   \n",
       "488157          2011        4         3    1        5          5        0   \n",
       "\n",
       "       RELTYPE STATE  \n",
       "6            1    18  \n",
       "23           2    44  \n",
       "287979       1     4  \n",
       "404424       1     4  \n",
       "488157       1     4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to drop 'ABT_INMATE_ID' as it will not be used for our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "complete_rows.drop('ABT_INMATE_ID', axis=1, inplace = True)\n",
    "complete_rows['recidivism'] = complete_rows['recidivism'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I remove all the rows that have \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows = complete_rows[complete_rows.RELEASEYR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.ADMTYPE != 9]\n",
    "complete_rows = complete_rows[complete_rows.OFFGENERAL != 9]\n",
    "complete_rows = complete_rows[complete_rows.ADMITYR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.OFFDETAIL != 99]\n",
    "complete_rows = complete_rows[complete_rows.RACE != 9]\n",
    "complete_rows = complete_rows[complete_rows.AGEADMIT != 9]\n",
    "complete_rows.drop('EDUCATION', axis=1, inplace=True) # missing all values\n",
    "complete_rows = complete_rows[complete_rows.MAND_PRISREL_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.MAND_PRISREL_YEAR != 9993]\n",
    "complete_rows = complete_rows[complete_rows.PROJ_PRISREL_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.PARELIG_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.OFFDETAIL != 9]\n",
    "complete_rows = complete_rows[complete_rows.SENTLGTH != 9]\n",
    "complete_rows = complete_rows[complete_rows.AGERELEASE != 9]\n",
    "complete_rows = complete_rows[complete_rows.RELTYPE != 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created complete_rows2 as random forest and Decision Tree do not require standardScaling of continuous variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows.head()\n",
    "complete_rows2 = complete_rows.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying StandardScaler for continuous variables (only applicable to neural network dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate data standardization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "columns = ['ADMITYR', 'RELEASEYR', 'MAND_PRISREL_YEAR', 'PROJ_PRISREL_YEAR', 'PARELIG_YEAR']\n",
    "for i in columns:\n",
    "    # load data\n",
    "    data = complete_rows[i].values.reshape(-1,1)\n",
    "    # create scaler\n",
    "    scaler = StandardScaler()\n",
    "    # fit and transform in one step\n",
    "    complete_rows[i] = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.046774</td>\n",
       "      <td>-0.097914</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>-0.270770</td>\n",
       "      <td>-0.099855</td>\n",
       "      <td>-0.159550</td>\n",
       "      <td>-0.050625</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.210267</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.392387</td>\n",
       "      <td>-2.294955</td>\n",
       "      <td>0.245169</td>\n",
       "      <td>-0.529367</td>\n",
       "      <td>0.382303</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.073314</td>\n",
       "      <td>-0.406095</td>\n",
       "      <td>-0.117229</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942323</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>-0.020234</td>\n",
       "      <td>-0.221186</td>\n",
       "      <td>0.215792</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.326905</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.085927</td>\n",
       "      <td>0.271903</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         recidivism SEX ADMTYPE OFFGENERAL   ADMITYR  RELEASEYR  \\\n",
       "6                 1   2       3          3  0.281023   0.018399   \n",
       "23                1   1       1          3  0.071847  -0.270770   \n",
       "287979            0   1       1          2  1.117729   1.175077   \n",
       "404424            0   1       1          1  1.117729   1.464246   \n",
       "488157            0   1       2          1  1.117729   1.175077   \n",
       "491650            0   1       1          1  1.117729   1.464246   \n",
       "743263            0   1       2          2 -1.392387  -2.294955   \n",
       "2086862           0   2       2          1  0.490200   0.018399   \n",
       "2942323           0   2       2          2  0.699376   0.596738   \n",
       "3075560           0   1       1          1  1.326905   1.464246   \n",
       "\n",
       "         MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR SENTLGTH  \\\n",
       "6                -0.046774          -0.097914      0.015980        2   \n",
       "23               -0.099855          -0.159550     -0.050625        1   \n",
       "287979            0.032847           0.148631      0.149188        3   \n",
       "404424            0.059387           0.210267      0.182490        3   \n",
       "488157            0.032847           0.148631      0.082584        4   \n",
       "491650            0.032847           0.148631      0.149188        3   \n",
       "743263            0.245169          -0.529367      0.382303        2   \n",
       "2086862          -0.073314          -0.406095     -0.117229        2   \n",
       "2942323          -0.020234          -0.221186      0.215792        2   \n",
       "3075560           0.085927           0.271903      0.182490        2   \n",
       "\n",
       "        OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6              12    1        2          2        0       1    18  \n",
       "23             12    2        4          4        1       2    44  \n",
       "287979         10    1        5          5        1       1     4  \n",
       "404424          1    1        4          4        1       1     4  \n",
       "488157          3    1        5          5        0       1     4  \n",
       "491650          3    1        3          3        1       1     4  \n",
       "743263          7    3        2          2        1       1     6  \n",
       "2086862         5    2        4          4        0       2     6  \n",
       "2942323        11    1        3          3        0       1     6  \n",
       "3075560         6    3        2          2        0       1     8  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001</td>\n",
       "      <td>2021</td>\n",
       "      <td>2002</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942323</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2007</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         recidivism SEX ADMTYPE OFFGENERAL  ADMITYR  RELEASEYR  \\\n",
       "6                 1   2       3          3     2008       2009   \n",
       "23                1   1       1          3     2007       2008   \n",
       "287979            0   1       1          2     2012       2013   \n",
       "404424            0   1       1          1     2012       2014   \n",
       "488157            0   1       2          1     2012       2013   \n",
       "491650            0   1       1          1     2012       2014   \n",
       "743263            0   1       2          2     2000       2001   \n",
       "2086862           0   2       2          1     2009       2009   \n",
       "2942323           0   2       2          2     2010       2011   \n",
       "3075560           0   1       1          1     2013       2014   \n",
       "\n",
       "         MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR SENTLGTH  \\\n",
       "6                     2010               2009          2009        2   \n",
       "23                    2008               2008          2007        1   \n",
       "287979                2013               2013          2013        3   \n",
       "404424                2014               2014          2014        3   \n",
       "488157                2013               2013          2011        4   \n",
       "491650                2013               2013          2013        3   \n",
       "743263                2021               2002          2020        2   \n",
       "2086862               2009               2004          2005        2   \n",
       "2942323               2011               2007          2015        2   \n",
       "3075560               2015               2015          2014        2   \n",
       "\n",
       "        OFFDETAIL RACE AGEADMIT AGERELEASE TIMESRVD RELTYPE STATE  \n",
       "6              12    1        2          2        0       1    18  \n",
       "23             12    2        4          4        1       2    44  \n",
       "287979         10    1        5          5        1       1     4  \n",
       "404424          1    1        4          4        1       1     4  \n",
       "488157          3    1        5          5        0       1     4  \n",
       "491650          3    1        3          3        1       1     4  \n",
       "743263          7    3        2          2        1       1     6  \n",
       "2086862         5    2        4          4        0       2     6  \n",
       "2942323        11    1        3          3        0       1     6  \n",
       "3075560         6    3        2          2        0       1     8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking of class imbalance in dataset to see if under/oversampling of dataset is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check for class imbalance in data set\n",
    "def print_data_perc(data_frame, col):\n",
    "    \"\"\"Function used to print class distribution\"\"\"\n",
    "    try:\n",
    "        # Stores value counts\n",
    "        col_vals = data_frame[col].value_counts()\n",
    "        # Resets index to make index a column in data frame\n",
    "        col_vals = col_vals.reset_index()\n",
    "        # If the number of unique instances in column exceeds 20 print warning\n",
    "        if len(col_vals['index']) > 20:\n",
    "            print('Warning: values in column are more than 20 \\nPlease try a column with lower value counts!')\n",
    "        # Else it calculates/prints percentage for each unique value in column\n",
    "        else:\n",
    "            # Create a function to output the percentage\n",
    "            f = lambda x, y: 100 * (x / sum(y))\n",
    "            for i in range(0, len(col_vals['index'])):\n",
    "                print('{0} accounts for {1:.2f}% of the {2} column'\\\n",
    "                      .format(col_vals['index'][i],\n",
    "                              f(col_vals[col].iloc[i],\n",
    "                                col_vals[col]),\n",
    "                              col))\n",
    "    # try-except block goes here if it can't find the column in data frame\n",
    "    except KeyError as e:\n",
    "        print('{0}: Not found'.format(e))\n",
    "        print('Please choose the right column name!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounts for 54.45% of the recidivism column\n",
      "1 accounts for 45.55% of the recidivism column\n"
     ]
    }
   ],
   "source": [
    "print_data_perc(complete_rows, 'recidivism') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounts for 54.45% of the recidivism column\n",
      "1 accounts for 45.55% of the recidivism column\n"
     ]
    }
   ],
   "source": [
    "print_data_perc(complete_rows2, 'recidivism') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split for Neural Network, Random Forest and Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1,y1 are the datasets for neural network. X2,y2 are datasets for Random Forest and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = complete_rows.iloc[:, 1:17]\n",
    "y1 = complete_rows.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = complete_rows2.iloc[:, 1:17]\n",
    "y2 = complete_rows2.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train1 (462720, 16) (462720, 1)\n",
      "Test1 (198309, 16) (198309, 1)\n",
      "Train2 (462720, 16) (462720, 1)\n",
      "Test2 (198309, 16) (198309, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train1', X_train.shape, y_train.shape)\n",
    "print('Test1', X_test.shape, y_test.shape)\n",
    "print('Train2', X_train2.shape, y_train2.shape)\n",
    "print('Test2', X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid and tanh should not be used as activation function for the hidden layer. This is because of the vanishing gradient problem, i.e., if your input is on a higher side (where sigmoid goes flat) then the gradient will be near zero. This will cause very slow or no learning during backpropagation as weights will be updated with really small values.\n",
    "\n",
    "Detailed explanation here: http://cs231n.github.io/neural-networks-1/#actfun\n",
    "\n",
    "The best function for hidden layers is thus ReLu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=However%2C%20neural%20networks%20with%20two,more%20than%20one%20hidden%20layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 16 elements for input.(Thus no need to flattenlayer) It would produce 17 outputs in return\n",
    "model.add(Dense(15, activation='relu', input_shape=(16,)))\n",
    "\n",
    "#Adding another hidden layer\n",
    "model.add(Dense(15, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                255       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 511\n",
      "Trainable params: 511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.2186586 ,  0.35513806,  0.00496298, -0.00116113,  0.05735415,\n",
       "          0.20402181,  0.25006658,  0.09821099, -0.37063378,  0.18102902,\n",
       "          0.3451761 , -0.01311097, -0.31107283, -0.35037214,  0.41158313],\n",
       "        [ 0.3506471 ,  0.30627632, -0.35751498,  0.04330182, -0.10499436,\n",
       "         -0.22535941,  0.29160702, -0.2698148 , -0.11350566, -0.08031747,\n",
       "          0.43991745,  0.00129268,  0.01901627,  0.05360383,  0.19328684],\n",
       "        [ 0.28616393, -0.31721532,  0.04821077,  0.4008667 ,  0.31757718,\n",
       "         -0.38745242, -0.22978902, -0.10865366, -0.41072   , -0.3432525 ,\n",
       "          0.40961677, -0.05733454, -0.12943503,  0.10707116,  0.26566422],\n",
       "        [ 0.13885278,  0.14245743, -0.18787321,  0.04673874, -0.41588983,\n",
       "          0.316231  , -0.34919056,  0.13625193,  0.39271098,  0.00582707,\n",
       "          0.43377948, -0.19085431, -0.05878037,  0.33528948, -0.19605865],\n",
       "        [ 0.25205016, -0.3227447 , -0.16584376, -0.28376132, -0.04935262,\n",
       "         -0.21950674,  0.3872524 ,  0.15308815, -0.3367892 , -0.17197376,\n",
       "         -0.17022955,  0.37207836,  0.29457468,  0.17161053, -0.12673661],\n",
       "        [-0.25945365,  0.15516144, -0.42582187, -0.07712156, -0.43765768,\n",
       "         -0.29256707,  0.02919072,  0.31143606, -0.02024516,  0.01003578,\n",
       "         -0.28476354,  0.02136046, -0.3927569 ,  0.09927154, -0.07010064],\n",
       "        [-0.20564885, -0.3607099 ,  0.12755454, -0.39334986, -0.0809899 ,\n",
       "         -0.28449136, -0.291961  , -0.22244765, -0.23762234,  0.3024696 ,\n",
       "         -0.34319672, -0.1096715 , -0.01511887, -0.3348935 ,  0.25598598],\n",
       "        [-0.26270095, -0.10765719,  0.07293034,  0.39526266,  0.10680264,\n",
       "         -0.18633449,  0.33296907, -0.05610892, -0.3383702 ,  0.34995103,\n",
       "          0.13715881,  0.36442798,  0.06904596,  0.07525486, -0.356971  ],\n",
       "        [-0.06717199,  0.01667324, -0.397452  , -0.41680047, -0.03729591,\n",
       "         -0.23870847,  0.14423817, -0.12758467, -0.28325772,  0.41215622,\n",
       "          0.40211928,  0.40747964, -0.29498392, -0.16269329,  0.03696465],\n",
       "        [-0.27957422, -0.18913779, -0.1982369 , -0.21431929, -0.2960878 ,\n",
       "         -0.39065334,  0.10844165,  0.36270398, -0.30590355, -0.13731334,\n",
       "          0.321505  , -0.3049547 ,  0.25197804,  0.211303  ,  0.12385792],\n",
       "        [ 0.32461083,  0.14251673,  0.19571346, -0.05097014, -0.2412743 ,\n",
       "          0.2244438 , -0.21050182,  0.03443292,  0.37755442, -0.35759825,\n",
       "         -0.00174505, -0.21507797, -0.22563149, -0.32612628,  0.37692785],\n",
       "        [ 0.07120913,  0.15523928, -0.28912845,  0.0134784 , -0.22554831,\n",
       "          0.09360927, -0.0157885 ,  0.34762454,  0.24684525,  0.25798547,\n",
       "          0.35674793, -0.33974048, -0.17868957,  0.22976017,  0.06700718],\n",
       "        [ 0.20656478,  0.0449124 ,  0.02291524, -0.40264732, -0.4366612 ,\n",
       "         -0.32043052,  0.35431916, -0.3516857 ,  0.30391353,  0.39724022,\n",
       "         -0.12899143,  0.43256128, -0.39219385, -0.26892638, -0.02489033],\n",
       "        [-0.04459783, -0.23456416,  0.432759  ,  0.3571142 ,  0.30918628,\n",
       "          0.1297456 , -0.34617633,  0.2568335 ,  0.42070335,  0.1238429 ,\n",
       "          0.01535016, -0.40306824,  0.22936809,  0.00560451, -0.07801345],\n",
       "        [ 0.2772895 , -0.23965542,  0.05761471,  0.376817  ,  0.34560686,\n",
       "          0.07950664,  0.14345598, -0.28322187,  0.4158666 ,  0.08362913,\n",
       "          0.3132915 ,  0.42698258,  0.18373072,  0.01324898,  0.32182556],\n",
       "        [-0.03237864, -0.32369387,  0.36671174,  0.00643101,  0.40000933,\n",
       "         -0.15103066,  0.08483654, -0.02281541, -0.1356352 , -0.29557174,\n",
       "         -0.40967318,  0.08348978,  0.41233623,  0.20586914,  0.21719748]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 3.05417299e-01, -9.86471772e-02, -1.24951959e-01,\n",
       "          2.47815967e-01, -5.99193573e-03,  3.44544232e-01,\n",
       "          4.33279216e-01, -3.13953817e-01, -3.06054145e-01,\n",
       "          2.63121903e-01,  1.06242537e-01, -3.54453444e-01,\n",
       "          1.68394089e-01,  8.10997486e-02, -3.18836123e-01],\n",
       "        [ 3.09624135e-01, -3.32657397e-02,  3.55522931e-02,\n",
       "          1.65512383e-01, -1.28532708e-01, -2.87296832e-01,\n",
       "          1.59634709e-01, -4.37897116e-01,  4.09569144e-01,\n",
       "         -3.12784374e-01, -2.80268937e-01, -2.23717898e-01,\n",
       "          9.61453319e-02, -3.27788174e-01,  2.60372877e-01],\n",
       "        [ 4.35218394e-01,  2.67452419e-01,  3.23728681e-01,\n",
       "          2.18498766e-01, -1.80175424e-01, -2.64339954e-01,\n",
       "         -1.50902748e-01,  2.76389837e-01,  1.81669533e-01,\n",
       "          2.01800704e-01, -3.73286128e-01,  1.42348111e-01,\n",
       "         -3.07348251e-01,  2.45627940e-01,  3.77267897e-02],\n",
       "        [-2.31154397e-01,  2.63542533e-02, -4.29119498e-01,\n",
       "          1.02712929e-01,  3.65804732e-01, -7.25995600e-02,\n",
       "          2.80976474e-01,  2.96295464e-01,  3.78776133e-01,\n",
       "          4.46392238e-01, -8.29656422e-02,  3.78561258e-01,\n",
       "         -5.48418462e-02, -2.99074650e-01, -1.35977626e-01],\n",
       "        [-1.35621399e-01,  3.19006622e-01,  3.29265118e-01,\n",
       "          9.49168205e-03, -2.47518614e-01, -2.44173288e-01,\n",
       "          3.85173857e-02,  2.85953939e-01,  3.10842097e-02,\n",
       "         -5.97515702e-02,  3.87766242e-01, -3.07370186e-01,\n",
       "         -1.62693024e-01,  1.00191593e-01,  2.77283013e-01],\n",
       "        [ 3.70028853e-01, -2.22705185e-01,  3.74232233e-02,\n",
       "         -1.35341078e-01, -1.30746871e-01,  3.58424485e-01,\n",
       "         -2.73685217e-01, -1.02218390e-02, -1.26689702e-01,\n",
       "         -3.11583042e-01,  3.72984529e-01, -2.66855299e-01,\n",
       "         -9.86590981e-02, -6.45650029e-02,  1.08458996e-02],\n",
       "        [ 3.06575298e-01,  2.73205101e-01, -1.68426722e-01,\n",
       "         -3.31393570e-01, -3.43615025e-01, -3.37129503e-01,\n",
       "         -2.60232449e-01,  4.03926790e-01,  4.31031287e-01,\n",
       "          2.70781398e-01, -1.42981648e-01, -1.13019884e-01,\n",
       "         -2.47182861e-01,  1.03558183e-01,  2.87576079e-01],\n",
       "        [-2.12237239e-02,  2.95479834e-01,  1.19968534e-01,\n",
       "         -1.72222555e-01,  1.12955391e-01,  2.88004696e-01,\n",
       "         -2.91195989e-01,  2.55791903e-01,  2.92902052e-01,\n",
       "          2.50818431e-01, -2.05025077e-02, -2.91757673e-01,\n",
       "          6.44026399e-02,  4.23942268e-01,  3.90231669e-01],\n",
       "        [-4.18694109e-01,  7.21353292e-03,  2.58078158e-01,\n",
       "         -2.60671020e-01,  1.62088871e-01, -2.38755643e-02,\n",
       "         -7.42130876e-02, -3.93233031e-01, -3.00107062e-01,\n",
       "          4.07584310e-02,  2.91299164e-01,  3.82356524e-01,\n",
       "         -3.02952558e-01, -1.82846665e-01, -3.98050755e-01],\n",
       "        [ 2.64871240e-01,  2.70932615e-01, -8.87196064e-02,\n",
       "         -3.83118898e-01,  5.82137108e-02, -4.20684367e-01,\n",
       "          2.39818335e-01,  4.34183776e-02,  2.99259186e-01,\n",
       "          2.60956466e-01,  4.03272212e-02,  3.13209772e-01,\n",
       "         -2.38505363e-01, -1.87810242e-01, -4.15401340e-01],\n",
       "        [-3.53749424e-01,  1.35899067e-01,  4.14300978e-01,\n",
       "         -2.05428675e-01, -2.81272382e-01, -2.56254435e-01,\n",
       "         -1.85579330e-01, -2.26174831e-01,  1.89140916e-01,\n",
       "          2.81238377e-01, -3.50641131e-01, -1.68987244e-01,\n",
       "          8.16885233e-02, -4.43314016e-01, -1.78379536e-01],\n",
       "        [ 2.06476927e-01, -3.63154948e-01,  3.78211558e-01,\n",
       "         -1.44871354e-01, -8.74940753e-02, -3.63029242e-01,\n",
       "         -1.46332830e-01,  2.53936946e-01,  2.85655379e-01,\n",
       "          4.21434879e-01,  1.78753138e-01, -1.83128804e-01,\n",
       "          3.46556664e-01,  2.24645019e-01,  3.92909348e-01],\n",
       "        [ 5.90919852e-02,  3.95775080e-01,  4.41180706e-01,\n",
       "          2.70195901e-02, -6.74190223e-02,  2.68251956e-01,\n",
       "          3.64293993e-01,  3.09450209e-01, -1.05902195e-01,\n",
       "         -2.83336401e-01, -4.26378608e-01, -3.76533598e-01,\n",
       "          4.36143458e-01,  1.74832582e-01, -7.85712600e-02],\n",
       "        [ 1.63208127e-01, -6.59523904e-02,  1.06074810e-01,\n",
       "         -3.64565045e-01, -3.76392186e-01, -2.87976146e-01,\n",
       "          3.02586198e-01,  2.17368662e-01,  5.75610995e-03,\n",
       "         -3.43882322e-01, -1.88975424e-01, -3.67278308e-01,\n",
       "          4.24867511e-01,  4.00578797e-01,  1.25202596e-01],\n",
       "        [ 3.25940192e-01, -1.45122349e-01, -1.48491114e-01,\n",
       "          3.08432937e-01,  1.26094639e-01, -2.15381384e-04,\n",
       "          4.22184110e-01,  1.38626039e-01,  1.60079002e-02,\n",
       "          3.70243847e-01, -2.06003487e-01, -2.23986477e-01,\n",
       "          7.92202950e-02, -4.24009204e-01,  9.08799171e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-0.07839125],\n",
       "        [ 0.537113  ],\n",
       "        [-0.24032533],\n",
       "        [ 0.505819  ],\n",
       "        [ 0.3023026 ],\n",
       "        [-0.4376896 ],\n",
       "        [-0.51165926],\n",
       "        [ 0.42788535],\n",
       "        [ 0.13383776],\n",
       "        [-0.48233086],\n",
       "        [ 0.00971079],\n",
       "        [-0.2326613 ],\n",
       "        [-0.36454237],\n",
       "        [ 0.04759735],\n",
       "        [ 0.19278628]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used binary_crossentropy because our target variable y is a binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# An epoch is a single pass through the entire training set, followed by testing of the verification set. \n",
    "#The batch size that you specify in the code above defines the number of samples that going to be propagated through the network. \n",
    "#Also, by doing this, you optimize the efficiency because you make sure that you don’t load too many input patterns into memory at the same time.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/38955/how-does-the-validation-split-parameter-of-keras-fit-function-work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir ./Graph\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7230/7230 [==============================] - 7s 877us/step - loss: 0.6534 - accuracy: 0.6195\n",
      "Epoch 2/20\n",
      "7230/7230 [==============================] - 6s 857us/step - loss: 0.6025 - accuracy: 0.6652\n",
      "Epoch 3/20\n",
      "7230/7230 [==============================] - 6s 865us/step - loss: 0.5656 - accuracy: 0.7020\n",
      "Epoch 4/20\n",
      "7230/7230 [==============================] - 6s 879us/step - loss: 0.5424 - accuracy: 0.7248\n",
      "Epoch 5/20\n",
      "7230/7230 [==============================] - 6s 867us/step - loss: 0.5297 - accuracy: 0.7305\n",
      "Epoch 6/20\n",
      "7230/7230 [==============================] - 6s 815us/step - loss: 0.5176 - accuracy: 0.7388\n",
      "Epoch 7/20\n",
      "7230/7230 [==============================] - 6s 836us/step - loss: 0.5075 - accuracy: 0.7434\n",
      "Epoch 8/20\n",
      "7230/7230 [==============================] - 6s 835us/step - loss: 0.5011 - accuracy: 0.74600s - loss: 0.5011 - ac\n",
      "Epoch 9/20\n",
      "7230/7230 [==============================] - 6s 837us/step - loss: 0.4969 - accuracy: 0.7481\n",
      "Epoch 10/20\n",
      "7230/7230 [==============================] - 6s 871us/step - loss: 0.4935 - accuracy: 0.7493\n",
      "Epoch 11/20\n",
      "7230/7230 [==============================] - 6s 866us/step - loss: 0.4939 - accuracy: 0.7490\n",
      "Epoch 12/20\n",
      "7230/7230 [==============================] - 6s 856us/step - loss: 0.4909 - accuracy: 0.7511\n",
      "Epoch 13/20\n",
      "7230/7230 [==============================] - 6s 843us/step - loss: 0.4887 - accuracy: 0.7533\n",
      "Epoch 14/20\n",
      "7230/7230 [==============================] - 6s 847us/step - loss: 0.4885 - accuracy: 0.7530\n",
      "Epoch 15/20\n",
      "7230/7230 [==============================] - 6s 853us/step - loss: 0.4874 - accuracy: 0.7541\n",
      "Epoch 16/20\n",
      "7230/7230 [==============================] - 6s 856us/step - loss: 0.4847 - accuracy: 0.7556\n",
      "Epoch 17/20\n",
      "7230/7230 [==============================] - 6s 850us/step - loss: 0.4845 - accuracy: 0.7558\n",
      "Epoch 18/20\n",
      "7230/7230 [==============================] - 6s 852us/step - loss: 0.4841 - accuracy: 0.7556\n",
      "Epoch 19/20\n",
      "7230/7230 [==============================] - 6s 842us/step - loss: 0.4823 - accuracy: 0.7566\n",
      "Epoch 20/20\n",
      "7230/7230 [==============================] - 6s 887us/step - loss: 0.4819 - accuracy: 0.7566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d141094220>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is the parameter specifying how big chunk of training data will be used for validation. It’s a float value between 0 and 1. Validation data is not used for the training, but to evaluate the loss and the accuracy.\n",
    "\n",
    "#For example: validation_split=0.3 will cause that 30% of the training data will be used for validation\n",
    "model.fit(X_train, y_train,epochs=20, batch_size=64, verbose=1, callbacks=[keras.callbacks.TensorBoard(log_dir='./Graph', write_graph=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model, filename= \"nn1.gv\", title=\"My first neural network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizing Score for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    rounded = [round(x[0]) for x in y_pred]\n",
    "    return accuracy_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596276517959346"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_custom_loss_func(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Permutation Importance for feature selection for NN (Not sure if this is recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(model, scoring = score, random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# perm = PermutationImportance(model, scoring = 'r2', random_state=1).fit(X_train, y_train)\n",
    "# eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN model test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4774656 ],\n",
       "       [0.09636477],\n",
       "       [0.971063  ],\n",
       "       ...,\n",
       "       [0.00246406],\n",
       "       [0.70421135],\n",
       "       [0.8981146 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6198/6198 [==============================] - 4s 649us/step - loss: 0.4830 - accuracy: 0.7566\n",
      "[0.48303136229515076, 0.7566424012184143]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[96382, 11525],\n",
       "       [36735, 53667]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7566424115899933\n",
      "Precision:  0.8232145048472205\n",
      "Recall:  0.5936483706112696\n",
      "F1 score:  0.6898337982184402\n",
      "Cohen Kappa Score:  0.49811029485867675\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \n",
    "print(\"Accuracy: \", accuracy_score(y_test, rounded))\n",
    "print(\"Precision: \", precision_score(y_test, rounded))\n",
    "print(\"Recall: \", recall_score(y_test, rounded))\n",
    "print(\"F1 score: \", f1_score(y_test, rounded))\n",
    "print(\"Cohen Kappa Score: \", cohen_kappa_score(y_test, rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-6bab64811ae4>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train2,y_train2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, oob_score=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train2,y_train2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'feature_importances'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SEX', 0.014478559943283833)\n",
      "('ADMTYPE', 0.03955091028693849)\n",
      "('OFFGENERAL', 0.0339124938846298)\n",
      "('ADMITYR', 0.08903662548670026)\n",
      "('RELEASEYR', 0.06990081929813141)\n",
      "('MAND_PRISREL_YEAR', 0.08200835590488123)\n",
      "('PROJ_PRISREL_YEAR', 0.06873896721787207)\n",
      "('PARELIG_YEAR', 0.13580035647445943)\n",
      "('SENTLGTH', 0.045575993756498366)\n",
      "('OFFDETAIL', 0.07154332806340437)\n",
      "('RACE', 0.04517759960695708)\n",
      "('AGEADMIT', 0.04272676654317511)\n",
      "('AGERELEASE', 0.04374962385377173)\n",
      "('TIMESRVD', 0.07033561702697692)\n",
      "('RELTYPE', 0.021061024647149377)\n",
      "('STATE', 0.12640295800517057)\n"
     ]
    }
   ],
   "source": [
    "feat_labels = ['SEX','ADMTYPE','OFFGENERAL','ADMITYR','RELEASEYR','MAND_PRISREL_YEAR','PROJ_PRISREL_YEAR','PARELIG_YEAR','SENTLGTH','OFFDETAIL','RACE','AGEADMIT','AGERELEASE','TIMESRVD','RELTYPE','STATE']\n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn SelectfromModel for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(n_estimators=500,\n",
       "                                                 oob_score=True))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train2, y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMITYR\n",
      "RELEASEYR\n",
      "MAND_PRISREL_YEAR\n",
      "PROJ_PRISREL_YEAR\n",
      "PARELIG_YEAR\n",
      "OFFDETAIL\n",
      "TIMESRVD\n",
      "STATE\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train2)\n",
    "X_important_test = sfm.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-56fba80e5bf6>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf_important.fit(X_important_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, oob_score=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7662133337367442\n",
      "Precision score:  0.7614705044172129\n",
      "Recall score:  0.709364837061127\n"
     ]
    }
   ],
   "source": [
    "y_pred2=clf.predict(X_test2)\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision score: \", precision_score(y_test2, y_pred2))\n",
    "print(\"Recall score: \", recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87819, 20088],\n",
       "       [26274, 64128]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7467991871271601\n",
      "Precision score:  0.7448877623144605\n",
      "Recall score:  0.6761354837282361\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (8 Features) Model\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_important_pred))\n",
    "print(\"Precision score: \", precision_score(y_test2, y_important_pred))\n",
    "print(\"Recall score: \", recall_score(y_test2, y_important_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86973, 20934],\n",
       "       [29278, 61124]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, y_important_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_train2, y_train2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, accuracy for model after feature selection has slightly deproved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_test2,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfpimp import *\n",
    "imp = importances(model, X_test2, y_test2) # permutation\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Decision Tree Classifier Model (Not going to be included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dtc = dtc.fit(X_train2,y_train2)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_dtc = dtc.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the optimized max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "   dt.fit(X_train2,y_train2)\n",
    "   train_pred = dt.predict(X_train2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train2, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous train results\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label= 'Train AUC')\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label= 'Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above in the graph, max_depth 7 is the most optimum (intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth = 7)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dtc = dtc.fit(X_train2,y_train2)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_dtc = dtc.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of pruned decision tree using sklearn graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtc, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feat_labels,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('dtree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectfromModel used for decision tree classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(clf)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train2, y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using features selected from Random Forrest and Decision Tree on NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using features selected from random forest model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = complete_rows[['ADMITYR','RELEASEYR','MAND_PRISREL_YEAR','PROJ_PRISREL_YEAR','PARELIG_YEAR','OFFDETAIL','TIMESRVD','STATE']]\n",
    "y3 = complete_rows.iloc[:, 0:1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model2 = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 8 elements for input. (Thus no need to flattenlayer) It would produce 32 outputs in return\n",
    "model2.add(Dense(7, activation='relu', input_shape=(8,)))\n",
    "\n",
    "# # model.add(Flatten)\n",
    "\n",
    "# # Add one hidden layer \n",
    "model2.add(Dense(7, activation='relu'))\n",
    "\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "# model2.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model2.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 7)                 63        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.10863483,  0.56163234, -0.55499107, -0.17730406,  0.00082058,\n",
       "          0.42029887, -0.32411146],\n",
       "        [-0.27738312,  0.36895376,  0.6141152 ,  0.06015027,  0.25840884,\n",
       "          0.04869813,  0.14064449],\n",
       "        [ 0.19043797,  0.08721691, -0.2555291 , -0.27869272,  0.06503552,\n",
       "         -0.15546769, -0.09265679],\n",
       "        [ 0.2639724 , -0.35665283, -0.4741883 , -0.09771848,  0.55489784,\n",
       "          0.5920133 , -0.4476304 ],\n",
       "        [-0.01158768, -0.5898957 ,  0.59468824,  0.39791328,  0.35825527,\n",
       "          0.40594822, -0.05185127],\n",
       "        [ 0.29552037,  0.55482596,  0.6001896 , -0.1680949 , -0.07977498,\n",
       "          0.37001985, -0.01830143],\n",
       "        [ 0.03481859, -0.23959672,  0.08622211,  0.12131739, -0.41073066,\n",
       "          0.22608316, -0.42611748],\n",
       "        [ 0.51219696, -0.32502526, -0.3571233 ,  0.03838426,  0.38066643,\n",
       "         -0.1734395 ,  0.6315296 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.579991  ,  0.11751866,  0.4792403 ,  0.08019954, -0.65301234,\n",
       "          0.6328672 , -0.38179696],\n",
       "        [ 0.15072173, -0.4883712 ,  0.35351968, -0.16196555, -0.11674792,\n",
       "          0.5283034 ,  0.05984998],\n",
       "        [ 0.42992365,  0.37957275,  0.00351638,  0.34790933,  0.04201984,\n",
       "         -0.6282233 ,  0.25593477],\n",
       "        [-0.24796388,  0.29029083, -0.10628486, -0.58933973,  0.01696235,\n",
       "          0.5245656 , -0.58581215],\n",
       "        [ 0.08637851, -0.33353093, -0.15947121,  0.63977563, -0.35580298,\n",
       "         -0.5989076 ,  0.63334537],\n",
       "        [-0.52139294, -0.29236048, -0.32545152, -0.45675656,  0.43141794,\n",
       "         -0.62031245, -0.0117172 ],\n",
       "        [-0.16427821,  0.45687294,  0.05154389,  0.43198907, -0.56657106,\n",
       "          0.5568155 ,  0.27194488]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.30462307],\n",
       "        [-0.545377  ],\n",
       "        [-0.0249269 ],\n",
       "        [-0.5903251 ],\n",
       "        [-0.49782237],\n",
       "        [ 0.31830674],\n",
       "        [-0.7786759 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model2.output_shape\n",
    "\n",
    "# Model summary\n",
    "model2.summary()\n",
    "\n",
    "# Model config\n",
    "model2.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7230/7230 [==============================] - 6s 767us/step - loss: 0.7105 - accuracy: 0.6040\n",
      "Epoch 2/20\n",
      "7230/7230 [==============================] - 6s 787us/step - loss: 0.6246 - accuracy: 0.6328\n",
      "Epoch 3/20\n",
      "7230/7230 [==============================] - 6s 786us/step - loss: 0.6026 - accuracy: 0.6643\n",
      "Epoch 4/20\n",
      "7230/7230 [==============================] - 6s 818us/step - loss: 0.5800 - accuracy: 0.6949\n",
      "Epoch 5/20\n",
      "7230/7230 [==============================] - 7s 912us/step - loss: 0.5723 - accuracy: 0.6987\n",
      "Epoch 6/20\n",
      "7230/7230 [==============================] - 7s 1ms/step - loss: 0.5689 - accuracy: 0.7011\n",
      "Epoch 7/20\n",
      "7230/7230 [==============================] - 7s 938us/step - loss: 0.5634 - accuracy: 0.7029\n",
      "Epoch 8/20\n",
      "7230/7230 [==============================] - 5s 737us/step - loss: 0.5628 - accuracy: 0.7063\n",
      "Epoch 9/20\n",
      "7230/7230 [==============================] - 6s 843us/step - loss: 0.5561 - accuracy: 0.7081\n",
      "Epoch 10/20\n",
      "7230/7230 [==============================] - 7s 970us/step - loss: 0.5556 - accuracy: 0.7096\n",
      "Epoch 11/20\n",
      "7230/7230 [==============================] - 6s 844us/step - loss: 0.5514 - accuracy: 0.7109\n",
      "Epoch 12/20\n",
      "7230/7230 [==============================] - 7s 943us/step - loss: 0.5509 - accuracy: 0.7119\n",
      "Epoch 13/20\n",
      "7230/7230 [==============================] - 6s 810us/step - loss: 0.5475 - accuracy: 0.7142\n",
      "Epoch 14/20\n",
      "7230/7230 [==============================] - 6s 783us/step - loss: 0.5456 - accuracy: 0.7139\n",
      "Epoch 15/20\n",
      "7230/7230 [==============================] - 7s 951us/step - loss: 0.5439 - accuracy: 0.7151\n",
      "Epoch 16/20\n",
      "7230/7230 [==============================] - 6s 896us/step - loss: 0.5413 - accuracy: 0.7165\n",
      "Epoch 17/20\n",
      "7230/7230 [==============================] - 6s 803us/step - loss: 0.5416 - accuracy: 0.7149\n",
      "Epoch 18/20\n",
      "7230/7230 [==============================] - 7s 1ms/step - loss: 0.5409 - accuracy: 0.7149\n",
      "Epoch 19/20\n",
      "7230/7230 [==============================] - 6s 866us/step - loss: 0.5391 - accuracy: 0.7171\n",
      "Epoch 20/20\n",
      "7230/7230 [==============================] - 8s 1ms/step - loss: 0.5391 - accuracy: 0.7163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d1413838e0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train3, y_train3, epochs=20, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "ann_viz(model2, filename= \"nn2.gv\", title=\"Neural Network revised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76780, 31127],\n",
       "       [26009, 64393]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = model2.predict(X_test3)\n",
    "y_pred3\n",
    "rounded2 = [round(x[0]) for x in y_pred3]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test3, rounded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.711883979042807\n",
      "Precision:  0.6741310720268007\n",
      "Recall:  0.7122961881374306\n",
      "F1 score:  0.6926883316659673\n",
      "Cohen Kappa Score:  0.42189746196889955\n"
     ]
    }
   ],
   "source": [
    "# Accuracy \n",
    "print(\"Accuracy: \", accuracy_score(y_test3, rounded2))\n",
    "print(\"Precision: \", precision_score(y_test3, rounded2))\n",
    "print(\"Recall: \", recall_score(y_test3, rounded2))\n",
    "print(\"F1 score: \", f1_score(y_test3, rounded2))\n",
    "print(\"Cohen Kappa Score: \", cohen_kappa_score(y_test3, rounded2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using features selected from decision tree model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = complete_rows[['ADMITYR','RELEASEYR','PARELIG_YEAR','TIMESRVD','STATE']]\n",
    "y4 = complete_rows.iloc[:, 0:1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model3 = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 8 elements for input. (Thus no need to flattenlayer) It would produce 32 outputs in return\n",
    "model3.add(Dense(32, activation='relu', input_shape=(5,)))\n",
    "\n",
    "# model.add(Flatten)\n",
    "\n",
    "# Add one hidden layer \n",
    "model3.add(Dense(64, activation='relu'))\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model3.add(Dense(1, activation='sigmoid')) #activation: \"relu\", research more on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model output shape\n",
    "model3.output_shape\n",
    "\n",
    "# Model summary\n",
    "model3.summary()\n",
    "\n",
    "# Model config\n",
    "model3.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_train4, y_train4, epochs=15, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model3.predict(X_test4)\n",
    "y_pred4\n",
    "rounded3 = [round(x[0]) for x in y_pred4]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test4, rounded3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy \n",
    "print(\"Accuracy: \", accuracy_score(y_test3, rounded3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3\n",
    "\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/decision-tree-classification-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
