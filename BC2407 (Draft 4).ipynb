{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "%matplotlib inline \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from urllib.request import urlopen \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import OrderedDict  \n",
    "data_path = r\"C:\\Users\\jethr\\ICPSR_36404-V2\\ICPSR_36404\\DS0001\\36404-0001-Data.tsv\"\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/deep-learning-python#preprocess\n",
    "\n",
    "https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "https://stackoverflow.com/questions/43798377/one-hot-encode-categorical-variables-and-scale-continuous-ones-simultaneouely\n",
    "\n",
    "https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df(filename):\n",
    "    df = pd.read_csv(data_path, header=0, sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3248: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID        object\n",
      "SEX                   int64\n",
      "ADMTYPE               int64\n",
      "OFFGENERAL            int64\n",
      "EDUCATION             int64\n",
      "ADMITYR               int64\n",
      "RELEASEYR             int64\n",
      "MAND_PRISREL_YEAR    object\n",
      "PROJ_PRISREL_YEAR    object\n",
      "PARELIG_YEAR         object\n",
      "SENTLGTH             object\n",
      "OFFDETAIL             int64\n",
      "RACE                  int64\n",
      "AGEADMIT              int64\n",
      "AGERELEASE           object\n",
      "TIMESRVD              int64\n",
      "RELTYPE              object\n",
      "STATE                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = build_df(data_path)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\" \", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A012015000000091071</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A022015000000096906</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A042015000000118649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A062015000000167469</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A132015000000550479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1968</td>\n",
       "      <td>1972</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "0  A012015000000091071    1        1           2          9     2006   \n",
       "1  A022015000000096906    1        3           3          9     2008   \n",
       "2  A042015000000118649    1        1           1          9     2013   \n",
       "3  A062015000000167469    1        2           2          9     1996   \n",
       "4  A132015000000550479    1        1           1          9     1968   \n",
       "\n",
       "   RELEASEYR MAND_PRISREL_YEAR PROJ_PRISREL_YEAR PARELIG_YEAR SENTLGTH  \\\n",
       "0       2010               NaN               NaN          NaN        4   \n",
       "1       2008               NaN               NaN          NaN        0   \n",
       "2       2014              2014              2014          NaN        0   \n",
       "3       1996               NaN               NaN          NaN        2   \n",
       "4       1972              1978               NaN          NaN        3   \n",
       "\n",
       "   OFFDETAIL  RACE  AGEADMIT AGERELEASE  TIMESRVD RELTYPE  STATE  \n",
       "0         10     9         3          3         2       3      1  \n",
       "1         12     1         3          3         0     NaN      2  \n",
       "2          6     1         1          1         0       1      4  \n",
       "3          7     1         2          2         0       1      6  \n",
       "4          4     1         1          1         2       1     13  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "#df = df.convert_objects(convert_numeric=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type :  <class 'pandas.core.frame.DataFrame'>\n",
      "Data dims :  (10907333, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type : \", type(df))\n",
    "print(\"Data dims : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID              0\n",
      "SEX                        0\n",
      "ADMTYPE                    0\n",
      "OFFGENERAL                 0\n",
      "EDUCATION                  0\n",
      "ADMITYR                    0\n",
      "RELEASEYR                  0\n",
      "MAND_PRISREL_YEAR    7209317\n",
      "PROJ_PRISREL_YEAR    4662333\n",
      "PARELIG_YEAR         8148769\n",
      "SENTLGTH               20063\n",
      "OFFDETAIL                  0\n",
      "RACE                       0\n",
      "AGEADMIT                   0\n",
      "AGERELEASE           1200886\n",
      "TIMESRVD                   0\n",
      "RELTYPE              1809372\n",
      "STATE                      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f3d0b7e438>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "missing_data.plot(kind='bar', color='Red', title=\"Number of Rows Missing Data\", grid=True).legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above graph, most of the missing data are related to the year when the prisoner is going to be released. For example, some columns such as PARELIG_YEAR are missing almost 80% of their values. Therefore, we cannot impute the values in these columns as more data is missing than available. It is best that we drop all missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "6       A182015000000019353    2        3           3          9     2008   \n",
       "23      A442015000000038143    1        1           3          9     2007   \n",
       "287979  A042015000000273326    1        1           2          9     2012   \n",
       "404424  A042015000000190084    1        1           1          9     2012   \n",
       "488157  A042015000000224709    1        2           1          9     2012   \n",
       "\n",
       "        RELEASEYR MAND_PRISREL_YEAR PROJ_PRISREL_YEAR PARELIG_YEAR SENTLGTH  \\\n",
       "6            2009              2010              2009         2009        2   \n",
       "23           2008              2008              2008         2007        1   \n",
       "287979       2013              2013              2013         2013        3   \n",
       "404424       2014              2014              2014         2014        3   \n",
       "488157       2013              2013              2013         2011        4   \n",
       "\n",
       "        OFFDETAIL  RACE  AGEADMIT AGERELEASE  TIMESRVD RELTYPE  STATE  \n",
       "6              12     1         2          2         0       1     18  \n",
       "23             12     2         4          4         1       2     44  \n",
       "287979         10     1         5          5         1       1      4  \n",
       "404424          1     1         4          4         1       1      4  \n",
       "488157          3     1         5          5         0       1      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "complete_rows['MAND_PRISREL_YEAR'] = complete_rows['MAND_PRISREL_YEAR'].astype(str).astype(int)\n",
    "complete_rows['PROJ_PRISREL_YEAR'] = complete_rows['PROJ_PRISREL_YEAR'].astype(str).astype(int)\n",
    "complete_rows['PARELIG_YEAR'] = complete_rows['PARELIG_YEAR'].astype(str).astype(int)\n",
    "complete_rows['AGERELEASE'] = complete_rows['AGERELEASE'].astype(str).astype(int)\n",
    "complete_rows['RELTYPE'] = complete_rows['RELTYPE'].astype(str).astype(int)\n",
    "complete_rows['SENTLGTH'] = complete_rows['SENTLGTH'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABT_INMATE_ID        object\n",
      "SEX                   int64\n",
      "ADMTYPE               int64\n",
      "OFFGENERAL            int64\n",
      "EDUCATION             int64\n",
      "ADMITYR               int64\n",
      "RELEASEYR             int64\n",
      "MAND_PRISREL_YEAR     int32\n",
      "PROJ_PRISREL_YEAR     int32\n",
      "PARELIG_YEAR          int32\n",
      "SENTLGTH              int32\n",
      "OFFDETAIL             int64\n",
      "RACE                  int64\n",
      "AGEADMIT              int64\n",
      "AGERELEASE            int32\n",
      "TIMESRVD              int64\n",
      "RELTYPE               int32\n",
      "STATE                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(complete_rows.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720189\n"
     ]
    }
   ],
   "source": [
    "print(len(complete_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, eventhough we have dropped more than 90% of the data, we are still left with 720K rows which is more than enough to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  \\\n",
       "6       A182015000000019353    2        3           3          9     2008   \n",
       "23      A442015000000038143    1        1           3          9     2007   \n",
       "287979  A042015000000273326    1        1           2          9     2012   \n",
       "404424  A042015000000190084    1        1           1          9     2012   \n",
       "488157  A042015000000224709    1        2           1          9     2012   \n",
       "\n",
       "        RELEASEYR  MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR  \\\n",
       "6            2009               2010               2009          2009   \n",
       "23           2008               2008               2008          2007   \n",
       "287979       2013               2013               2013          2013   \n",
       "404424       2014               2014               2014          2014   \n",
       "488157       2013               2013               2013          2011   \n",
       "\n",
       "        SENTLGTH  OFFDETAIL  RACE  AGEADMIT  AGERELEASE  TIMESRVD  RELTYPE  \\\n",
       "6              2         12     1         2           2         0        1   \n",
       "23             1         12     2         4           4         1        2   \n",
       "287979         3         10     1         5           5         1        1   \n",
       "404424         3          1     1         4           4         1        1   \n",
       "488157         4          3     1         5           5         0        1   \n",
       "\n",
       "        STATE  \n",
       "6          18  \n",
       "23         44  \n",
       "287979      4  \n",
       "404424      4  \n",
       "488157      4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data file contains one record for each separate term in prison. An individual person may have more than one record, but all will be assigned the same Abt_Inmate_ID value. Thus, we iterate through the dataset to find deuplicate copies of Abt_Inmate_ID value which indicates that the felony has recommited a crime. We will mark 0 as non-repeated offender and 1 as repeated offender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = complete_rows.set_index('ABT_INMATE_ID').index.duplicated(keep=False) #If the index is duplicated, TRUE, else FALSE\n",
    "repeat = repeat * 1 #Change true and false to 1 and 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recividism = [x + 0 for x in repeat] #add 1 to all the numbers in repeat.\n",
    "se = pd.Series(recividism)\n",
    "complete_rows.insert(0, 'recidivism', se.values) #insert this row inside\n",
    "#it will be binary from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>ABT_INMATE_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>A182015000000019353</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>A442015000000038143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000273326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000190084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>A042015000000224709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recidivism        ABT_INMATE_ID  SEX  ADMTYPE  OFFGENERAL  EDUCATION  \\\n",
       "6                1  A182015000000019353    2        3           3          9   \n",
       "23               1  A442015000000038143    1        1           3          9   \n",
       "287979           0  A042015000000273326    1        1           2          9   \n",
       "404424           0  A042015000000190084    1        1           1          9   \n",
       "488157           0  A042015000000224709    1        2           1          9   \n",
       "\n",
       "        ADMITYR  RELEASEYR  MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  \\\n",
       "6          2008       2009               2010               2009   \n",
       "23         2007       2008               2008               2008   \n",
       "287979     2012       2013               2013               2013   \n",
       "404424     2012       2014               2014               2014   \n",
       "488157     2012       2013               2013               2013   \n",
       "\n",
       "        PARELIG_YEAR  SENTLGTH  OFFDETAIL  RACE  AGEADMIT  AGERELEASE  \\\n",
       "6               2009         2         12     1         2           2   \n",
       "23              2007         1         12     2         4           4   \n",
       "287979          2013         3         10     1         5           5   \n",
       "404424          2014         3          1     1         4           4   \n",
       "488157          2011         4          3     1         5           5   \n",
       "\n",
       "        TIMESRVD  RELTYPE  STATE  \n",
       "6              0        1     18  \n",
       "23             1        2     44  \n",
       "287979         1        1      4  \n",
       "404424         1        1      4  \n",
       "488157         0        1      4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "complete_rows.drop('ABT_INMATE_ID', axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recidivism  SEX  ADMTYPE  OFFGENERAL  EDUCATION  ADMITYR  RELEASEYR  \\\n",
       "6                1    2        3           3          9     2008       2009   \n",
       "23               1    1        1           3          9     2007       2008   \n",
       "287979           0    1        1           2          9     2012       2013   \n",
       "404424           0    1        1           1          9     2012       2014   \n",
       "488157           0    1        2           1          9     2012       2013   \n",
       "\n",
       "        MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR  SENTLGTH  \\\n",
       "6                    2010               2009          2009         2   \n",
       "23                   2008               2008          2007         1   \n",
       "287979               2013               2013          2013         3   \n",
       "404424               2014               2014          2014         3   \n",
       "488157               2013               2013          2011         4   \n",
       "\n",
       "        OFFDETAIL  RACE  AGEADMIT  AGERELEASE  TIMESRVD  RELTYPE  STATE  \n",
       "6              12     1         2           2         0        1     18  \n",
       "23             12     2         4           4         1        2     44  \n",
       "287979         10     1         5           5         1        1      4  \n",
       "404424          1     1         4           4         1        1      4  \n",
       "488157          3     1         5           5         0        1      4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I remove all the rows that have \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows = complete_rows[complete_rows.RELEASEYR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.ADMTYPE != 9]\n",
    "complete_rows = complete_rows[complete_rows.OFFGENERAL != 9]\n",
    "complete_rows = complete_rows[complete_rows.ADMITYR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.OFFDETAIL != 99]\n",
    "complete_rows = complete_rows[complete_rows.RACE != 9]\n",
    "complete_rows = complete_rows[complete_rows.AGEADMIT != 9]\n",
    "complete_rows.drop('EDUCATION', axis=1, inplace=True) # missing all values\n",
    "complete_rows = complete_rows[complete_rows.MAND_PRISREL_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.MAND_PRISREL_YEAR != 9993]\n",
    "complete_rows = complete_rows[complete_rows.PROJ_PRISREL_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.PARELIG_YEAR != 9999]\n",
    "complete_rows = complete_rows[complete_rows.OFFDETAIL != 9]\n",
    "complete_rows = complete_rows[complete_rows.SENTLGTH != 9]\n",
    "complete_rows = complete_rows[complete_rows.AGERELEASE != 9]\n",
    "complete_rows = complete_rows[complete_rows.RELTYPE != 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete_rows2 represent shanon random forest data while complete_rows represent ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_rows.head()\n",
    "complete_rows2 = complete_rows.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying StandardScaler for continuous variables (only applicable to neural network dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate data standardization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "columns = ['ADMITYR', 'RELEASEYR', 'MAND_PRISREL_YEAR', 'PROJ_PRISREL_YEAR', 'PARELIG_YEAR']\n",
    "for i in columns:\n",
    "    # load data\n",
    "    data = complete_rows[i].values.reshape(-1,1)\n",
    "    # create scaler\n",
    "    scaler = StandardScaler()\n",
    "    # fit and transform in one step\n",
    "    complete_rows[i] = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.046774</td>\n",
       "      <td>-0.097914</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>-0.270770</td>\n",
       "      <td>-0.099855</td>\n",
       "      <td>-0.159550</td>\n",
       "      <td>-0.050625</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.210267</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.175077</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117729</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.148631</td>\n",
       "      <td>0.149188</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.392387</td>\n",
       "      <td>-2.294955</td>\n",
       "      <td>0.245169</td>\n",
       "      <td>-0.529367</td>\n",
       "      <td>0.382303</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>-0.073314</td>\n",
       "      <td>-0.406095</td>\n",
       "      <td>-0.117229</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942323</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>-0.020234</td>\n",
       "      <td>-0.221186</td>\n",
       "      <td>0.215792</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.326905</td>\n",
       "      <td>1.464246</td>\n",
       "      <td>0.085927</td>\n",
       "      <td>0.271903</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         recidivism  SEX  ADMTYPE  OFFGENERAL   ADMITYR  RELEASEYR  \\\n",
       "6                 1    2        3           3  0.281023   0.018399   \n",
       "23                1    1        1           3  0.071847  -0.270770   \n",
       "287979            0    1        1           2  1.117729   1.175077   \n",
       "404424            0    1        1           1  1.117729   1.464246   \n",
       "488157            0    1        2           1  1.117729   1.175077   \n",
       "491650            0    1        1           1  1.117729   1.464246   \n",
       "743263            0    1        2           2 -1.392387  -2.294955   \n",
       "2086862           0    2        2           1  0.490200   0.018399   \n",
       "2942323           0    2        2           2  0.699376   0.596738   \n",
       "3075560           0    1        1           1  1.326905   1.464246   \n",
       "\n",
       "         MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR  SENTLGTH  \\\n",
       "6                -0.046774          -0.097914      0.015980         2   \n",
       "23               -0.099855          -0.159550     -0.050625         1   \n",
       "287979            0.032847           0.148631      0.149188         3   \n",
       "404424            0.059387           0.210267      0.182490         3   \n",
       "488157            0.032847           0.148631      0.082584         4   \n",
       "491650            0.032847           0.148631      0.149188         3   \n",
       "743263            0.245169          -0.529367      0.382303         2   \n",
       "2086862          -0.073314          -0.406095     -0.117229         2   \n",
       "2942323          -0.020234          -0.221186      0.215792         2   \n",
       "3075560           0.085927           0.271903      0.182490         2   \n",
       "\n",
       "         OFFDETAIL  RACE  AGEADMIT  AGERELEASE  TIMESRVD  RELTYPE  STATE  \n",
       "6               12     1         2           2         0        1     18  \n",
       "23              12     2         4           4         1        2     44  \n",
       "287979          10     1         5           5         1        1      4  \n",
       "404424           1     1         4           4         1        1      4  \n",
       "488157           3     1         5           5         0        1      4  \n",
       "491650           3     1         3           3         1        1      4  \n",
       "743263           7     3         2           2         1        1      6  \n",
       "2086862          5     2         4           4         0        2      6  \n",
       "2942323         11     1         3           3         0        1      6  \n",
       "3075560          6     3         2           2         0        1      8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidivism</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ADMTYPE</th>\n",
       "      <th>OFFGENERAL</th>\n",
       "      <th>ADMITYR</th>\n",
       "      <th>RELEASEYR</th>\n",
       "      <th>MAND_PRISREL_YEAR</th>\n",
       "      <th>PROJ_PRISREL_YEAR</th>\n",
       "      <th>PARELIG_YEAR</th>\n",
       "      <th>SENTLGTH</th>\n",
       "      <th>OFFDETAIL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>AGEADMIT</th>\n",
       "      <th>AGERELEASE</th>\n",
       "      <th>TIMESRVD</th>\n",
       "      <th>RELTYPE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287979</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404424</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491650</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001</td>\n",
       "      <td>2021</td>\n",
       "      <td>2002</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086862</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942323</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2007</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         recidivism  SEX  ADMTYPE  OFFGENERAL  ADMITYR  RELEASEYR  \\\n",
       "6                 1    2        3           3     2008       2009   \n",
       "23                1    1        1           3     2007       2008   \n",
       "287979            0    1        1           2     2012       2013   \n",
       "404424            0    1        1           1     2012       2014   \n",
       "488157            0    1        2           1     2012       2013   \n",
       "491650            0    1        1           1     2012       2014   \n",
       "743263            0    1        2           2     2000       2001   \n",
       "2086862           0    2        2           1     2009       2009   \n",
       "2942323           0    2        2           2     2010       2011   \n",
       "3075560           0    1        1           1     2013       2014   \n",
       "\n",
       "         MAND_PRISREL_YEAR  PROJ_PRISREL_YEAR  PARELIG_YEAR  SENTLGTH  \\\n",
       "6                     2010               2009          2009         2   \n",
       "23                    2008               2008          2007         1   \n",
       "287979                2013               2013          2013         3   \n",
       "404424                2014               2014          2014         3   \n",
       "488157                2013               2013          2011         4   \n",
       "491650                2013               2013          2013         3   \n",
       "743263                2021               2002          2020         2   \n",
       "2086862               2009               2004          2005         2   \n",
       "2942323               2011               2007          2015         2   \n",
       "3075560               2015               2015          2014         2   \n",
       "\n",
       "         OFFDETAIL  RACE  AGEADMIT  AGERELEASE  TIMESRVD  RELTYPE  STATE  \n",
       "6               12     1         2           2         0        1     18  \n",
       "23              12     2         4           4         1        2     44  \n",
       "287979          10     1         5           5         1        1      4  \n",
       "404424           1     1         4           4         1        1      4  \n",
       "488157           3     1         5           5         0        1      4  \n",
       "491650           3     1         3           3         1        1      4  \n",
       "743263           7     3         2           2         1        1      6  \n",
       "2086862          5     2         4           4         0        2      6  \n",
       "2942323         11     1         3           3         0        1      6  \n",
       "3075560          6     3         2           2         0        1      8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_rows2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check for class imbalance in data set\n",
    "def print_data_perc(data_frame, col):\n",
    "    \"\"\"Function used to print class distribution\"\"\"\n",
    "    try:\n",
    "        # Stores value counts\n",
    "        col_vals = data_frame[col].value_counts()\n",
    "        # Resets index to make index a column in data frame\n",
    "        col_vals = col_vals.reset_index()\n",
    "        # If the number of unique instances in column exceeds 20 print warning\n",
    "        if len(col_vals['index']) > 20:\n",
    "            print('Warning: values in column are more than 20 \\nPlease try a column with lower value counts!')\n",
    "        # Else it calculates/prints percentage for each unique value in column\n",
    "        else:\n",
    "            # Create a function to output the percentage\n",
    "            f = lambda x, y: 100 * (x / sum(y))\n",
    "            for i in range(0, len(col_vals['index'])):\n",
    "                print('{0} accounts for {1:.2f}% of the {2} column'\\\n",
    "                      .format(col_vals['index'][i],\n",
    "                              f(col_vals[col].iloc[i],\n",
    "                                col_vals[col]),\n",
    "                              col))\n",
    "    # try-except block goes here if it can't find the column in data frame\n",
    "    except KeyError as e:\n",
    "        print('{0}: Not found'.format(e))\n",
    "        print('Please choose the right column name!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounts for 54.45% of the recidivism column\n",
      "1 accounts for 45.55% of the recidivism column\n"
     ]
    }
   ],
   "source": [
    "print_data_perc(complete_rows, 'recidivism') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounts for 54.45% of the recidivism column\n",
      "1 accounts for 45.55% of the recidivism column\n"
     ]
    }
   ],
   "source": [
    "print_data_perc(complete_rows2, 'recidivism') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1,y1 are the datasets for neural network. X2,y2 are datasets for random forsest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = complete_rows.iloc[:, 1:17]\n",
    "y1 = complete_rows.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = complete_rows2.iloc[:, 1:17]\n",
    "y2 = complete_rows2.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train1 (462720, 16) (462720, 1)\n",
      "Test1 (198309, 16) (198309, 1)\n",
      "Train2 (462720, 16) (462720, 1)\n",
      "Test2 (198309, 16) (198309, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train1', X_train.shape, y_train.shape)\n",
    "print('Test1', X_test.shape, y_test.shape)\n",
    "print('Train2', X_train2.shape, y_train2.shape)\n",
    "print('Test2', X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid and tanh should not be used as activation function for the hidden layer. This is because of the vanishing gradient problem, i.e., if your input is on a higher side (where sigmoid goes flat) then the gradient will be near zero. This will cause very slow or no learning during backpropagation as weights will be updated with really small values.\n",
    "\n",
    "Detailed explanation here: http://cs231n.github.io/neural-networks-1/#actfun\n",
    "\n",
    "The best function for hidden layers is thus ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 16 elements for input. (Thus no need to flattenlayer) It would produce 32 outputs in return\n",
    "model.add(Dense(32, activation='relu', input_shape=(16,)))\n",
    "\n",
    "# model.add(Flatten)\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid')) #activation: \"relu\", research more on this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 44,257\n",
      "Trainable params: 44,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.34725985, -0.26796392,  0.19133362, -0.0082956 ,  0.18560699,\n",
       "         -0.2757014 ,  0.13014922,  0.0088231 ,  0.03502056, -0.2534188 ,\n",
       "         -0.3287015 ,  0.22540721, -0.00048023,  0.11353526, -0.00843865,\n",
       "         -0.09774089,  0.12399265, -0.00791213,  0.35135826,  0.21712717,\n",
       "         -0.3150149 ,  0.33533034,  0.18751594, -0.12687145,  0.07926574,\n",
       "         -0.24029723,  0.12354842, -0.2801996 , -0.20412856, -0.2159972 ,\n",
       "         -0.12815651,  0.3068848 ],\n",
       "        [ 0.10845765, -0.15505682, -0.2228716 ,  0.10886252,  0.3120105 ,\n",
       "          0.21951875, -0.27855712,  0.27674785, -0.04796985, -0.02036259,\n",
       "         -0.10476105,  0.10845345,  0.2958155 ,  0.3035539 , -0.13119623,\n",
       "         -0.2042196 ,  0.13037345,  0.2795554 ,  0.0711014 , -0.02116624,\n",
       "          0.3033279 ,  0.01935443, -0.0460462 ,  0.16581377, -0.04636195,\n",
       "          0.27713928, -0.02633646,  0.031919  ,  0.18486044,  0.29874602,\n",
       "          0.28021762,  0.10787898],\n",
       "        [ 0.2993103 ,  0.33007672,  0.09353995,  0.33891258,  0.31100515,\n",
       "         -0.01266691, -0.0140799 ,  0.3364475 ,  0.30596504, -0.19499938,\n",
       "          0.16585425, -0.21297586,  0.17932811, -0.19812635,  0.15168229,\n",
       "         -0.1160038 ,  0.17330179,  0.09227344, -0.0643262 ,  0.24860051,\n",
       "         -0.00761113,  0.05056441, -0.04490653,  0.01819807,  0.2945756 ,\n",
       "         -0.09175932,  0.04147872,  0.30187312, -0.34724686,  0.03151599,\n",
       "         -0.2770056 ,  0.33113047],\n",
       "        [-0.13333307, -0.17195618, -0.27350986,  0.17923245,  0.03196603,\n",
       "         -0.21770027, -0.15815748,  0.18312898,  0.22126219,  0.2692881 ,\n",
       "         -0.09620306, -0.1614478 , -0.34350643,  0.06403911,  0.31767067,\n",
       "          0.15170178,  0.03063139,  0.00806481,  0.15285835,  0.2226161 ,\n",
       "         -0.16434245, -0.3196036 ,  0.07681009, -0.2515812 , -0.20565815,\n",
       "          0.23339543, -0.32001454,  0.05213758,  0.1899657 , -0.21323034,\n",
       "         -0.1390127 , -0.21970427],\n",
       "        [-0.27833298, -0.12863985, -0.15639532, -0.2733165 , -0.2351671 ,\n",
       "         -0.05457839,  0.3480989 , -0.29142758, -0.06958032,  0.24219754,\n",
       "          0.32184228,  0.05667529,  0.14603648,  0.20403185,  0.08041957,\n",
       "          0.26169804,  0.00450912, -0.14536305,  0.02766082,  0.33111522,\n",
       "         -0.01141319,  0.19395861,  0.30234107,  0.24718353, -0.30040452,\n",
       "         -0.10067263, -0.34644312, -0.01551992, -0.20843226,  0.25480136,\n",
       "          0.08875841, -0.1246525 ],\n",
       "        [ 0.12442458, -0.17578615, -0.05107576, -0.11084519,  0.19340423,\n",
       "          0.3126981 , -0.25918674,  0.16999015,  0.19734916,  0.3496888 ,\n",
       "         -0.30111942, -0.07285428, -0.1644167 ,  0.19625613, -0.20184362,\n",
       "          0.32953653,  0.02019811, -0.21410134,  0.11852503,  0.22789904,\n",
       "         -0.25948113, -0.33330655,  0.175643  , -0.03816432,  0.30529943,\n",
       "         -0.13723925, -0.26512635, -0.2633749 ,  0.20290866,  0.02297729,\n",
       "         -0.10469589,  0.33248213],\n",
       "        [-0.17301382, -0.3292301 , -0.28249726,  0.25303903,  0.11872277,\n",
       "         -0.3399301 ,  0.08329812, -0.05061591, -0.22104521, -0.07583854,\n",
       "         -0.10750321,  0.03202611,  0.24527672,  0.30031392,  0.17961171,\n",
       "         -0.22892264,  0.32399032, -0.27347243,  0.22542003,  0.05609071,\n",
       "         -0.32177484,  0.23497245, -0.26898152, -0.22027148, -0.28854498,\n",
       "          0.10333183, -0.06570855, -0.1586624 ,  0.19569638, -0.16422056,\n",
       "         -0.09979472, -0.24808225],\n",
       "        [-0.04254538, -0.00117841,  0.3119671 ,  0.07845679, -0.3314767 ,\n",
       "         -0.04459465, -0.3154791 , -0.06624407,  0.04515344,  0.13622501,\n",
       "         -0.15144703, -0.08773017, -0.01860902,  0.0624983 ,  0.14289004,\n",
       "          0.1306355 , -0.18315545,  0.31435367, -0.17732014, -0.03887719,\n",
       "         -0.00238493, -0.1860747 ,  0.08009174,  0.06656539, -0.28122425,\n",
       "         -0.17636855, -0.18491423,  0.22497067,  0.31906185, -0.2217221 ,\n",
       "         -0.04607198, -0.10788447],\n",
       "        [ 0.28689274, -0.27614674,  0.25830296, -0.24987459, -0.13828027,\n",
       "         -0.22967309,  0.3420606 ,  0.00392219,  0.3325865 ,  0.34264317,\n",
       "         -0.2352471 ,  0.24898353,  0.03394997, -0.07910019, -0.16664012,\n",
       "         -0.24794148, -0.3322769 ,  0.09266406,  0.3031681 , -0.08366856,\n",
       "          0.33838305, -0.08135918, -0.11910792, -0.33057415,  0.14343515,\n",
       "         -0.31721184, -0.1987561 , -0.27342102, -0.1300205 ,  0.3422055 ,\n",
       "          0.1804159 ,  0.02317831],\n",
       "        [-0.30160815,  0.14061782, -0.32580516, -0.00554577, -0.10536771,\n",
       "          0.30888858,  0.27409038, -0.15576573, -0.14723445,  0.18187657,\n",
       "         -0.00308809,  0.0385175 ,  0.0017882 , -0.16389653,  0.0708583 ,\n",
       "         -0.22518335,  0.199352  ,  0.09506828,  0.00084925,  0.11958012,\n",
       "         -0.23898518, -0.15631591,  0.2944543 ,  0.19522992,  0.3310984 ,\n",
       "          0.11742145, -0.11736684, -0.06733069, -0.06212211,  0.10473222,\n",
       "         -0.06642967,  0.19274434],\n",
       "        [-0.04499125,  0.29293373,  0.22079417,  0.18306896,  0.13153246,\n",
       "         -0.15869966, -0.3447248 , -0.00741994,  0.1807116 , -0.1249547 ,\n",
       "         -0.145242  , -0.24693492, -0.32290453, -0.12369257, -0.13259609,\n",
       "          0.08042201, -0.30696484, -0.06133378, -0.33644506,  0.33871743,\n",
       "          0.09271422, -0.19191247, -0.31452963,  0.19583353,  0.20626011,\n",
       "          0.26050875, -0.1411369 , -0.24898022,  0.16251102,  0.02202249,\n",
       "          0.07532695,  0.28094134],\n",
       "        [ 0.02962747,  0.24889997, -0.06779277,  0.02821252,  0.00817227,\n",
       "         -0.11673236,  0.23920783,  0.33859596,  0.03493181,  0.07281795,\n",
       "         -0.24722978, -0.23632462,  0.31271753,  0.02305263, -0.1599215 ,\n",
       "         -0.22694543,  0.16760704,  0.31589004,  0.03625733, -0.21626239,\n",
       "          0.20342067,  0.28172967, -0.3348895 , -0.08569753,  0.23650196,\n",
       "         -0.03891402, -0.2211392 , -0.3302858 , -0.00418806, -0.34098554,\n",
       "          0.19528368, -0.241718  ],\n",
       "        [-0.32161677, -0.22322133,  0.07442147,  0.03349739, -0.16945527,\n",
       "         -0.27191907, -0.0694806 ,  0.31674924,  0.33024517, -0.3390466 ,\n",
       "          0.13134906,  0.10498998, -0.09793746, -0.23802644,  0.2224969 ,\n",
       "          0.26597765, -0.08047992,  0.10206357, -0.25269926,  0.04705948,\n",
       "          0.08650026, -0.30023873, -0.01450735, -0.20683455, -0.06151357,\n",
       "          0.3365753 ,  0.06862399, -0.3352753 ,  0.29147515,  0.23921517,\n",
       "          0.2963123 ,  0.23365131],\n",
       "        [ 0.17197219,  0.17137584,  0.27846202,  0.2193059 , -0.1149267 ,\n",
       "         -0.25781226, -0.30543888,  0.33958694, -0.07985631, -0.22128224,\n",
       "         -0.26706585, -0.21281697, -0.13916771, -0.11803031,  0.19722888,\n",
       "          0.1356917 , -0.17766143,  0.22396895,  0.09790805,  0.1301778 ,\n",
       "          0.0617125 , -0.27771282,  0.34888384,  0.28509554,  0.2995589 ,\n",
       "          0.30850413,  0.16134873, -0.3339015 , -0.04083297, -0.12575945,\n",
       "          0.27545604, -0.24576283],\n",
       "        [ 0.16373673, -0.35086426,  0.05473408,  0.31359717, -0.21784635,\n",
       "         -0.05524051, -0.29387724,  0.14258572,  0.3018193 , -0.10599554,\n",
       "         -0.01509842,  0.32284698, -0.15472943,  0.27163747, -0.32869965,\n",
       "         -0.1766054 , -0.28681967,  0.24879518,  0.34842405, -0.30707452,\n",
       "         -0.326625  ,  0.11358634, -0.12926042,  0.09007657,  0.27150348,\n",
       "         -0.01951188, -0.19248642, -0.25525615, -0.15971766,  0.24582377,\n",
       "         -0.0261645 ,  0.26552   ],\n",
       "        [-0.10695639, -0.15385967, -0.17610697,  0.04060039, -0.20489454,\n",
       "          0.16311696,  0.04349107,  0.09613645, -0.0305917 , -0.28859615,\n",
       "         -0.09456655,  0.1917673 ,  0.29146364,  0.12319016,  0.16359577,\n",
       "         -0.06234607, -0.22281192,  0.19904062, -0.11525182, -0.1926379 ,\n",
       "          0.15451077,  0.25928506, -0.01619443,  0.09700081,  0.0797646 ,\n",
       "          0.15161148, -0.1396051 , -0.33219218, -0.02057382, -0.0370706 ,\n",
       "         -0.23057158,  0.23230979]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.14000934, -0.14648634,  0.13908148, ...,  0.13303792,\n",
       "         -0.1779905 ,  0.19411236],\n",
       "        [ 0.22211087,  0.06765985, -0.18204606, ...,  0.13422132,\n",
       "         -0.0442782 , -0.03047204],\n",
       "        [ 0.07071614, -0.05205399, -0.24802458, ...,  0.24906844,\n",
       "         -0.04416138, -0.13566846],\n",
       "        ...,\n",
       "        [ 0.1943664 ,  0.03768414, -0.03417611, ...,  0.03741044,\n",
       "         -0.0970068 ,  0.13175535],\n",
       "        [ 0.00218534, -0.21773338,  0.02252227, ..., -0.00831312,\n",
       "         -0.07924265, -0.1062206 ],\n",
       "        [ 0.07434922, -0.02683836,  0.0610792 , ..., -0.21672785,\n",
       "         -0.08567709,  0.06929153]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.11924438,  0.07769553,  0.00310336, ...,  0.14969765,\n",
       "          0.13471903, -0.0677876 ],\n",
       "        [-0.07663371,  0.1660109 , -0.08601198, ...,  0.05607255,\n",
       "          0.09071688,  0.0327765 ],\n",
       "        [-0.0129959 , -0.16626164, -0.04395111, ...,  0.17352132,\n",
       "          0.09210737,  0.0296592 ],\n",
       "        ...,\n",
       "        [-0.02347326,  0.09116225, -0.04424088, ...,  0.09621395,\n",
       "          0.08824559, -0.12979935],\n",
       "        [-0.01649871,  0.13861327,  0.12541242, ...,  0.07012254,\n",
       "          0.10489188, -0.06756148],\n",
       "        [-0.01621583,  0.15277044, -0.17349914, ..., -0.09203169,\n",
       "         -0.09137323,  0.11957254]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.07668129, -0.09721202, -0.02700746, ..., -0.03933668,\n",
       "          0.06523564, -0.0227311 ],\n",
       "        [-0.02066481, -0.06396395,  0.00954407, ...,  0.01175293,\n",
       "         -0.05708063,  0.10160479],\n",
       "        [-0.06413931,  0.06970704,  0.10139537, ...,  0.06897929,\n",
       "         -0.04442462,  0.08398384],\n",
       "        ...,\n",
       "        [-0.02244502,  0.11507913,  0.06894007, ...,  0.00122276,\n",
       "         -0.11963382,  0.04021791],\n",
       "        [ 0.04577377, -0.04456952, -0.11927933, ..., -0.05961984,\n",
       "         -0.07679144, -0.09582868],\n",
       "        [ 0.05589184, -0.02455461,  0.04815277, ...,  0.04129508,\n",
       "          0.03459531, -0.10820547]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[ 1.18248001e-01],\n",
       "        [-2.95459032e-02],\n",
       "        [-1.10073328e-01],\n",
       "        [ 1.16280720e-01],\n",
       "        [-4.01405990e-02],\n",
       "        [ 1.36298254e-01],\n",
       "        [-1.20934829e-01],\n",
       "        [-3.91566083e-02],\n",
       "        [-7.59366900e-02],\n",
       "        [ 1.00020304e-01],\n",
       "        [ 4.77160513e-03],\n",
       "        [-4.20158654e-02],\n",
       "        [ 7.88556486e-02],\n",
       "        [-9.34658572e-02],\n",
       "        [ 2.74337083e-02],\n",
       "        [ 1.16170004e-01],\n",
       "        [ 1.07575163e-01],\n",
       "        [ 8.62762332e-03],\n",
       "        [ 5.78857213e-02],\n",
       "        [-7.35763013e-02],\n",
       "        [-1.20640300e-01],\n",
       "        [ 4.02760059e-02],\n",
       "        [-5.08320481e-02],\n",
       "        [-1.38973087e-01],\n",
       "        [-6.29587471e-03],\n",
       "        [ 1.51294157e-01],\n",
       "        [ 5.22844791e-02],\n",
       "        [-1.19692817e-01],\n",
       "        [-3.02310288e-02],\n",
       "        [-1.25143528e-01],\n",
       "        [ 1.42556384e-01],\n",
       "        [ 1.23725727e-01],\n",
       "        [ 6.85260892e-02],\n",
       "        [-8.73204395e-02],\n",
       "        [-1.48742557e-01],\n",
       "        [ 1.37552515e-01],\n",
       "        [ 1.46647796e-01],\n",
       "        [ 4.55928445e-02],\n",
       "        [ 5.43014109e-02],\n",
       "        [ 7.98039138e-03],\n",
       "        [-1.39772817e-01],\n",
       "        [-5.11362702e-02],\n",
       "        [-9.76257771e-02],\n",
       "        [ 2.12488770e-02],\n",
       "        [-1.39833689e-01],\n",
       "        [-1.42896548e-01],\n",
       "        [-1.47885680e-02],\n",
       "        [-7.91805312e-02],\n",
       "        [-9.28425193e-02],\n",
       "        [-8.45352486e-02],\n",
       "        [ 1.37645751e-02],\n",
       "        [ 8.10762346e-02],\n",
       "        [ 8.27312469e-05],\n",
       "        [-1.47891536e-01],\n",
       "        [ 1.49363130e-02],\n",
       "        [-1.03374630e-01],\n",
       "        [-1.31059587e-01],\n",
       "        [ 1.00775808e-02],\n",
       "        [ 1.07228234e-01],\n",
       "        [ 6.74345642e-02],\n",
       "        [ 4.78774607e-02],\n",
       "        [ 6.80456609e-02],\n",
       "        [-7.21491575e-02],\n",
       "        [-8.59833062e-02],\n",
       "        [-1.45093352e-02],\n",
       "        [ 7.58125484e-02],\n",
       "        [-4.70558703e-02],\n",
       "        [-1.15875110e-01],\n",
       "        [ 1.50400445e-01],\n",
       "        [-2.44784951e-02],\n",
       "        [-5.60604334e-02],\n",
       "        [ 8.38334411e-02],\n",
       "        [ 5.56168705e-02],\n",
       "        [-1.33907869e-01],\n",
       "        [-7.46285990e-02],\n",
       "        [ 1.51187494e-01],\n",
       "        [-1.10264510e-01],\n",
       "        [-6.59953952e-02],\n",
       "        [-1.46652222e-01],\n",
       "        [-1.12320937e-01],\n",
       "        [-4.68644351e-02],\n",
       "        [ 2.70646363e-02],\n",
       "        [-3.56057137e-02],\n",
       "        [-8.11783001e-02],\n",
       "        [-4.51087952e-03],\n",
       "        [ 3.67628932e-02],\n",
       "        [-1.42491341e-01],\n",
       "        [-5.41006178e-02],\n",
       "        [ 1.29225537e-01],\n",
       "        [ 1.15045443e-01],\n",
       "        [-1.16358086e-01],\n",
       "        [-1.34657845e-01],\n",
       "        [-1.52469739e-01],\n",
       "        [ 8.42768997e-02],\n",
       "        [-5.02808765e-02],\n",
       "        [-1.49389386e-01],\n",
       "        [ 1.22950807e-01],\n",
       "        [ 1.42375991e-01],\n",
       "        [-6.20362014e-02],\n",
       "        [ 6.55899346e-02],\n",
       "        [-4.79462743e-03],\n",
       "        [-5.33149838e-02],\n",
       "        [-1.34745240e-01],\n",
       "        [ 2.18122154e-02],\n",
       "        [ 2.17495263e-02],\n",
       "        [ 9.49205905e-02],\n",
       "        [ 1.35642782e-01],\n",
       "        [-7.23384768e-02],\n",
       "        [ 4.54905480e-02],\n",
       "        [-5.09082228e-02],\n",
       "        [ 1.11155882e-01],\n",
       "        [ 1.40050992e-01],\n",
       "        [ 1.04269519e-01],\n",
       "        [-1.77600235e-02],\n",
       "        [-5.64421713e-02],\n",
       "        [ 6.13194555e-02],\n",
       "        [ 1.35468885e-01],\n",
       "        [ 9.40951407e-02],\n",
       "        [-6.15896136e-02],\n",
       "        [ 9.98215824e-02],\n",
       "        [ 1.11187950e-01],\n",
       "        [-1.23139158e-01],\n",
       "        [-7.28160143e-03],\n",
       "        [-1.04033560e-01],\n",
       "        [-4.67068478e-02],\n",
       "        [-1.33430392e-01],\n",
       "        [-1.38927162e-01],\n",
       "        [ 2.12683231e-02],\n",
       "        [ 1.50996998e-01],\n",
       "        [ 8.70301723e-02],\n",
       "        [-2.48477161e-02],\n",
       "        [ 1.50682524e-01],\n",
       "        [ 7.98822939e-02],\n",
       "        [-1.11022606e-01],\n",
       "        [-4.20268998e-02],\n",
       "        [ 4.72328067e-02],\n",
       "        [-5.92388809e-02],\n",
       "        [ 5.61797023e-02],\n",
       "        [ 4.63991314e-02],\n",
       "        [ 3.49335223e-02],\n",
       "        [ 9.10191983e-02],\n",
       "        [ 2.23605335e-03],\n",
       "        [-6.30840138e-02],\n",
       "        [-1.00026786e-01],\n",
       "        [-7.85882995e-02],\n",
       "        [ 6.60680383e-02],\n",
       "        [ 4.44865674e-02],\n",
       "        [ 1.24147534e-03],\n",
       "        [ 3.20618898e-02],\n",
       "        [ 4.96370941e-02],\n",
       "        [ 8.51136744e-02],\n",
       "        [ 7.96864182e-02],\n",
       "        [ 1.32013217e-01],\n",
       "        [-7.98683092e-02],\n",
       "        [ 1.39116362e-01],\n",
       "        [-1.32290930e-01],\n",
       "        [-1.01225749e-01],\n",
       "        [-7.58826360e-02],\n",
       "        [ 5.57262301e-02],\n",
       "        [-1.05425954e-01],\n",
       "        [-1.32649720e-01],\n",
       "        [ 1.49081931e-01],\n",
       "        [-6.10057637e-02],\n",
       "        [ 7.74983019e-02],\n",
       "        [-3.76546383e-03],\n",
       "        [ 1.32665589e-01],\n",
       "        [ 1.18203923e-01],\n",
       "        [-1.22677386e-01],\n",
       "        [-1.20804086e-01],\n",
       "        [ 4.74856645e-02],\n",
       "        [-8.24053138e-02],\n",
       "        [-1.33019477e-01],\n",
       "        [ 9.92591530e-02],\n",
       "        [ 9.73784477e-02],\n",
       "        [ 2.63134390e-02],\n",
       "        [ 1.84062719e-02],\n",
       "        [ 2.76045203e-02],\n",
       "        [-1.74593627e-02],\n",
       "        [-5.86133525e-02],\n",
       "        [ 1.29204080e-01],\n",
       "        [-1.50555596e-01],\n",
       "        [-6.89852834e-02],\n",
       "        [ 2.23118067e-02],\n",
       "        [ 9.00805742e-02],\n",
       "        [-2.15941668e-03],\n",
       "        [ 2.53297836e-02],\n",
       "        [ 1.15638897e-01],\n",
       "        [-3.72894704e-02],\n",
       "        [ 1.52449414e-01],\n",
       "        [-1.27019927e-01],\n",
       "        [-6.25820905e-02],\n",
       "        [-1.10551864e-02],\n",
       "        [ 2.95452923e-02],\n",
       "        [-8.15908238e-02],\n",
       "        [ 9.85652357e-02],\n",
       "        [ 1.02380052e-01],\n",
       "        [ 1.37657359e-01],\n",
       "        [ 1.34566739e-01],\n",
       "        [ 1.29570514e-02],\n",
       "        [ 1.28699079e-01],\n",
       "        [-1.17940716e-01],\n",
       "        [-4.81273308e-02],\n",
       "        [ 5.28681129e-02],\n",
       "        [-1.21131182e-01],\n",
       "        [-3.55585739e-02],\n",
       "        [ 1.35149017e-01],\n",
       "        [ 2.38682032e-02],\n",
       "        [-3.14763263e-02],\n",
       "        [ 5.00752032e-03],\n",
       "        [-5.12902513e-02],\n",
       "        [ 1.40494570e-01],\n",
       "        [ 3.55919451e-02],\n",
       "        [-1.07865430e-01],\n",
       "        [-9.54768211e-02],\n",
       "        [-1.80557370e-03],\n",
       "        [-1.42555207e-01],\n",
       "        [-1.08378902e-01],\n",
       "        [-6.54686615e-02],\n",
       "        [ 9.75325257e-02],\n",
       "        [-6.09758496e-03],\n",
       "        [-1.08362652e-01],\n",
       "        [-1.42695174e-01],\n",
       "        [ 6.38759136e-03],\n",
       "        [-9.99677330e-02],\n",
       "        [-4.09058332e-02],\n",
       "        [ 1.24551699e-01],\n",
       "        [ 3.34714353e-02],\n",
       "        [ 9.85607356e-02],\n",
       "        [-5.55246696e-02],\n",
       "        [-5.40608764e-02],\n",
       "        [ 1.08228192e-01],\n",
       "        [-4.60559130e-03],\n",
       "        [-1.28234535e-01],\n",
       "        [-3.10052931e-02],\n",
       "        [ 1.36856750e-01],\n",
       "        [ 3.29570621e-02],\n",
       "        [ 3.29948813e-02],\n",
       "        [ 1.43357173e-01],\n",
       "        [-8.13344419e-02],\n",
       "        [-6.49057999e-02],\n",
       "        [ 1.31486669e-01],\n",
       "        [ 1.41242638e-01],\n",
       "        [ 2.58918405e-02],\n",
       "        [ 7.98440874e-02],\n",
       "        [ 3.61618847e-02],\n",
       "        [ 1.49462223e-02],\n",
       "        [-2.45818496e-02],\n",
       "        [-9.20346305e-02],\n",
       "        [-6.85671493e-02],\n",
       "        [ 7.07701594e-02],\n",
       "        [ 1.42356291e-01],\n",
       "        [ 3.73409092e-02],\n",
       "        [ 1.41285554e-01],\n",
       "        [ 3.28631401e-02],\n",
       "        [ 9.40995812e-02],\n",
       "        [ 1.47069797e-01]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# An epoch is a single pass through the entire training set, followed by testing of the verification set. \n",
    "#The batch size that you specify in the code above defines the number of samples that going to be propagated through the network. \n",
    "#Also, by doing this, you optimize the efficiency because you make sure that you don’t load too many input patterns into memory at the same time.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/38955/how-does-the-validation-split-parameter-of-keras-fit-function-work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir ./Graph\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "212096/462720 [============>.................] - ETA: 6s - loss: 0.4489 - accuracy: 0.7771"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-cd3486fc8bdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#For example: validation_split=0.3 will cause that 30% of the training data will be used for validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./Graph'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#It is the parameter specifying how big chunk of training data will be used for validation. It’s a float value between 0 and 1. Validation data is not used for the training, but to evaluate the loss and the accuracy.\n",
    "\n",
    "#For example: validation_split=0.3 will cause that 30% of the training data will be used for validation\n",
    "model.fit(X_train, y_train,epochs=15, batch_size=64, verbose=1, callbacks=[keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1, write_graph=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "462720/462720 [==============================] - 12s 27us/step - loss: 0.5440 - accuracy: 0.7118\n",
      "Epoch 2/15\n",
      "462720/462720 [==============================] - 12s 26us/step - loss: 0.4924 - accuracy: 0.7481\n",
      "Epoch 3/15\n",
      "462720/462720 [==============================] - 15s 32us/step - loss: 0.4795 - accuracy: 0.7564\n",
      "Epoch 4/15\n",
      "462720/462720 [==============================] - 13s 27us/step - loss: 0.4724 - accuracy: 0.7617\n",
      "Epoch 5/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4674 - accuracy: 0.7650\n",
      "Epoch 6/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4635 - accuracy: 0.7667\n",
      "Epoch 7/15\n",
      "462720/462720 [==============================] - 13s 29us/step - loss: 0.4610 - accuracy: 0.7692\n",
      "Epoch 8/15\n",
      "462720/462720 [==============================] - 13s 27us/step - loss: 0.4588 - accuracy: 0.7702\n",
      "Epoch 9/15\n",
      "462720/462720 [==============================] - 13s 29us/step - loss: 0.4568 - accuracy: 0.7711\n",
      "Epoch 10/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4555 - accuracy: 0.7727\n",
      "Epoch 11/15\n",
      "462720/462720 [==============================] - 14s 30us/step - loss: 0.4537 - accuracy: 0.7738\n",
      "Epoch 12/15\n",
      "462720/462720 [==============================] - 15s 31us/step - loss: 0.4525 - accuracy: 0.7740\n",
      "Epoch 13/15\n",
      "462720/462720 [==============================] - 15s 32us/step - loss: 0.4518 - accuracy: 0.7743\n",
      "Epoch 14/15\n",
      "462720/462720 [==============================] - 13s 29us/step - loss: 0.4508 - accuracy: 0.7755\n",
      "Epoch 15/15\n",
      "462720/462720 [==============================] - 15s 31us/step - loss: 0.4494 - accuracy: 0.7761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f44acbda90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=15, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized Score for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    rounded = [round(x[0]) for x in y_pred]\n",
    "    return accuracy_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642567911693368"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_custom_loss_func(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "score = make_scorer(my_custom_loss_func, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Permutation Importance for feature selection for NN (Not sure if this is recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0009\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RACE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0031\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SEX\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0040\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RELTYPE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0045\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AGEADMIT\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0051\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AGERELEASE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0117\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SENTLGTH\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0132\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TIMESRVD\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0148\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PROJ_PRISREL_YEAR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0153\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                OFFGENERAL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 95.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0202\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                OFFDETAIL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 94.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0287\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MAND_PRISREL_YEAR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 93.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0361\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ADMTYPE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 86.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0932\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RELEASEYR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 85.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.1051\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ADMITYR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 85.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.1052\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                STATE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.1679\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PARELIG_YEAR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(model, scoring = score, random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.5026\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PARELIG_YEAR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3455\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ADMITYR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3104\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RELEASEYR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2874\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                STATE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1007\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ADMTYPE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0617\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                MAND_PRISREL_YEAR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0533\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                OFFDETAIL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0397\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PROJ_PRISREL_YEAR\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0388\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                OFFGENERAL\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0293\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SENTLGTH\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0288\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                TIMESRVD\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0113\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AGEADMIT\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0087\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AGERELEASE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.85%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0085\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RELTYPE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0059\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SEX\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                RACE\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(model, scoring = 'r2', random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1625623e-01],\n",
       "       [1.2840831e-01],\n",
       "       [9.7689277e-01],\n",
       "       ...,\n",
       "       [2.0350030e-04],\n",
       "       [5.3015143e-01],\n",
       "       [7.1049219e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198309/198309 [==============================] - 4s 18us/step\n",
      "[0.4598554443326957, 0.7699297666549683]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92716, 15191],\n",
       "       [30434, 59968]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699297560877217"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy \n",
    "accuracy_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910351784138192"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision \n",
    "precision_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6939780093360767"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "recall_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7393348731969455"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "f1_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5458241424003043"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cohen's kappa\n",
    "cohen_kappa_score(y_test, rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train2,y_train2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SEX', 0.014771441073150779)\n",
      "('ADMTYPE', 0.038969775300355856)\n",
      "('OFFGENERAL', 0.033716834543972715)\n",
      "('ADMITYR', 0.08735530265147028)\n",
      "('RELEASEYR', 0.07026354303488089)\n",
      "('MAND_PRISREL_YEAR', 0.08202167797714842)\n",
      "('PROJ_PRISREL_YEAR', 0.06838442595914573)\n",
      "('PARELIG_YEAR', 0.13401973787417334)\n",
      "('SENTLGTH', 0.04529650639831325)\n",
      "('OFFDETAIL', 0.07117848767801681)\n",
      "('RACE', 0.04570902656849937)\n",
      "('AGEADMIT', 0.042784155405744095)\n",
      "('AGERELEASE', 0.04378351502376401)\n",
      "('TIMESRVD', 0.07167858481021518)\n",
      "('RELTYPE', 0.020939625907742638)\n",
      "('STATE', 0.12912735979340656)\n"
     ]
    }
   ],
   "source": [
    "feat_labels = ['SEX','ADMTYPE','OFFGENERAL','ADMITYR','RELEASEYR','MAND_PRISREL_YEAR','PROJ_PRISREL_YEAR','PARELIG_YEAR','SENTLGTH','OFFDETAIL','RACE','AGEADMIT','AGERELEASE','TIMESRVD','RELTYPE','STATE']\n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using selectfromModel for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=500, n_jobs=None,\n",
       "                                                 oob_score=True,\n",
       "                                                 random_state=None, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train2, y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMITYR\n",
      "RELEASEYR\n",
      "MAND_PRISREL_YEAR\n",
      "PROJ_PRISREL_YEAR\n",
      "PARELIG_YEAR\n",
      "OFFDETAIL\n",
      "TIMESRVD\n",
      "STATE\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train2)\n",
    "X_important_test = sfm.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7659460740561447\n"
     ]
    }
   ],
   "source": [
    "y_pred2=clf.predict(X_test2)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7660469267658049\n"
     ]
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (8 Features) Model\n",
    "accuracy_score(y_test, y_important_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_train2, y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_test2,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfpimp import *\n",
    "imp = importances(model, X_test2, y_test2) # permutation\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth = 7)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train2,y_train2)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7243947576761519\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-6622689442c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 special_characters=True,feature_names = feat_labels,class_names=['0','1'])\n\u001b[0;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dtree.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feat_labels,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('dtree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the optimized max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "   dt.fit(X_train2,y_train2)\n",
    "   train_pred = dt.predict(X_train2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train2, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous train results\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test2)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label= 'Train AUC')\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label= 'Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen, max_depth 7 is the most optimum (intersect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectfromModel used for decision tree classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                 criterion='gini', max_depth=7,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 presort=False,\n",
       "                                                 random_state=None,\n",
       "                                                 splitter='best'),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = SelectFromModel(clf)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train2, y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMTYPE\n",
      "RELEASEYR\n",
      "PARELIG_YEAR\n",
      "TIMESRVD\n",
      "STATE\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using features selected from Random Forrest and Decision Tree on NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = complete_rows[['ADMITYR','RELEASEYR','MAND_PRISREL_YEAR','PROJ_PRISREL_YEAR','PARELIG_YEAR','OFFDETAIL','TIMESRVD','STATE']]\n",
    "y3 = complete_rows.iloc[:, 0:1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer of one-dimensional array with 16 elements for input. (Thus no need to flattenlayer) It would produce 32 outputs in return\n",
    "model.add(Dense(32, activation='relu', input_shape=(8,)))\n",
    "\n",
    "# model.add(Flatten)\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid')) #activation: \"relu\", research more on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 44,001\n",
      "Trainable params: 44,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.83643723e-01, -2.24532545e-01, -7.41958618e-02,\n",
       "          2.76281357e-01,  1.14810467e-01,  3.60356033e-01,\n",
       "          2.77477562e-01,  7.46526718e-02,  2.71164834e-01,\n",
       "          5.64962924e-02,  5.24864793e-02, -2.81626105e-01,\n",
       "         -2.14528620e-01, -1.43984303e-01,  2.89943159e-01,\n",
       "          1.45634294e-01, -3.37419420e-01, -8.67455900e-02,\n",
       "         -2.58563757e-01,  5.47110140e-02,  2.24864244e-01,\n",
       "         -8.46435726e-02,  5.23769557e-02, -3.41237187e-01,\n",
       "         -1.08476311e-01, -3.57581764e-01,  5.09346426e-02,\n",
       "          3.47224653e-01, -2.73198307e-01,  3.28019500e-01,\n",
       "         -3.08550715e-01, -2.47525543e-01],\n",
       "        [-3.15719098e-01,  7.85872340e-02,  1.97000802e-02,\n",
       "          7.15740919e-02, -1.96667090e-01, -3.39884430e-01,\n",
       "         -6.71288669e-02, -2.73657054e-01,  7.85797834e-03,\n",
       "          1.30249023e-01,  7.67363012e-02,  3.60350072e-01,\n",
       "         -3.82085711e-01,  1.01685971e-01,  2.74816751e-01,\n",
       "         -2.14836389e-01,  8.48891139e-02,  3.15833747e-01,\n",
       "          3.58547747e-01,  1.88341498e-01, -1.37857601e-01,\n",
       "         -3.53701681e-01,  3.78657043e-01, -2.93025374e-02,\n",
       "         -2.36706346e-01,  7.04876184e-02, -1.41057611e-01,\n",
       "         -5.13955951e-02, -2.00002193e-01,  1.19020760e-01,\n",
       "          3.98393571e-02,  2.10062981e-01],\n",
       "        [-3.12042803e-01,  1.92542672e-02, -2.83463091e-01,\n",
       "         -3.79225880e-01,  1.49177730e-01, -3.71791095e-01,\n",
       "          1.90016627e-03,  2.89920628e-01,  1.63448989e-01,\n",
       "          3.45385134e-01, -1.62094831e-02,  3.47750902e-01,\n",
       "          1.81292236e-01, -2.45256588e-01,  1.57196641e-01,\n",
       "         -2.72832185e-01,  9.90577042e-02,  1.77962303e-01,\n",
       "         -1.40164137e-01,  3.00501883e-01, -1.69149637e-02,\n",
       "          3.86277616e-01, -9.82780159e-02, -3.17358851e-01,\n",
       "          2.06035912e-01, -1.68117225e-01,  1.08667552e-01,\n",
       "          3.62914562e-01,  1.82431519e-01,  2.05634534e-02,\n",
       "          3.30214560e-01,  2.41298735e-01],\n",
       "        [-7.95897543e-02, -1.87915936e-01,  1.66088521e-01,\n",
       "         -2.86802173e-01,  1.39220238e-01, -3.05400282e-01,\n",
       "          3.85949612e-01,  2.13817060e-01, -2.96114743e-01,\n",
       "          3.04709852e-01,  3.62690628e-01,  3.00993323e-01,\n",
       "          2.03085423e-01,  2.49164283e-01,  2.13047802e-01,\n",
       "         -3.14879894e-01,  3.55529070e-01,  3.54952335e-01,\n",
       "          6.39578700e-03, -3.18702668e-01, -2.23426133e-01,\n",
       "          9.38120186e-02, -8.76309276e-02, -1.38443857e-01,\n",
       "         -1.62971526e-01, -2.96555221e-01, -2.14176163e-01,\n",
       "          4.74501252e-02,  3.22363973e-01, -3.51050705e-01,\n",
       "         -3.79572779e-01,  4.06397283e-02],\n",
       "        [ 3.85628045e-01, -2.71658093e-01, -1.31146401e-01,\n",
       "          2.22584367e-01, -3.68676603e-01, -1.23373270e-02,\n",
       "         -7.98416734e-02, -2.14807108e-01,  2.83380270e-01,\n",
       "          2.03999817e-01, -1.05910659e-01, -1.89771384e-01,\n",
       "         -6.26266003e-02,  4.09802794e-02, -2.23405361e-01,\n",
       "          8.67444277e-03, -2.59570241e-01,  6.99394941e-02,\n",
       "         -1.59113973e-01, -2.83978522e-01,  1.97272658e-01,\n",
       "         -8.43226910e-04, -2.25582719e-01, -2.45023698e-01,\n",
       "          1.38900101e-01, -1.04865938e-01, -1.24504149e-01,\n",
       "          2.20488548e-01, -1.11203164e-01,  2.30766833e-01,\n",
       "         -2.18991637e-01,  8.27349424e-02],\n",
       "        [-9.79213119e-02,  3.56487572e-01, -3.67746651e-01,\n",
       "         -1.98287457e-01, -1.53096318e-02, -4.66117859e-02,\n",
       "          1.50729716e-02, -2.29669511e-02, -2.39465266e-01,\n",
       "          3.13335717e-01,  5.63310087e-02, -1.24757171e-01,\n",
       "         -2.77574062e-02, -8.76508653e-02, -2.76066542e-01,\n",
       "         -3.75711441e-01, -2.42123514e-01,  5.24268150e-02,\n",
       "         -3.36170197e-05,  2.70946026e-02,  1.13681555e-01,\n",
       "          5.42334318e-02,  3.32050383e-01, -3.68963778e-01,\n",
       "         -1.56248048e-01, -3.60183895e-01, -1.89479604e-01,\n",
       "         -3.23333263e-01,  7.70551562e-02,  9.70494449e-02,\n",
       "          8.65396559e-02, -2.98449397e-03],\n",
       "        [ 3.46161067e-01, -2.07869306e-01,  8.31231177e-02,\n",
       "          9.77967381e-02,  3.43881488e-01, -1.35276258e-01,\n",
       "          1.66397512e-01,  1.91291451e-01, -3.79588127e-01,\n",
       "         -6.21856749e-02, -3.29233944e-01, -1.98214233e-01,\n",
       "         -3.73115242e-01,  3.69340777e-01,  7.05501437e-02,\n",
       "          2.58400202e-01,  1.67494118e-01,  2.65849233e-01,\n",
       "         -3.18324715e-01, -3.12723160e-01,  1.47374332e-01,\n",
       "         -5.76301515e-02,  1.67440355e-01, -1.35663629e-01,\n",
       "          3.39365005e-01,  3.19028497e-01, -2.39896476e-01,\n",
       "         -1.32666528e-02,  1.99022293e-02, -1.67458847e-01,\n",
       "         -1.49365827e-01,  3.72732043e-01],\n",
       "        [-2.49040186e-01, -2.12137595e-01,  1.89795136e-01,\n",
       "         -4.20103371e-02, -2.43138328e-01,  2.19649017e-01,\n",
       "         -3.11122268e-01, -3.23856652e-01, -3.41156572e-01,\n",
       "         -1.37915492e-01, -1.50683314e-01,  3.08231890e-01,\n",
       "         -8.95163119e-02, -2.11894214e-02, -2.75683999e-02,\n",
       "          2.65389085e-02,  5.72787821e-02,  1.61010623e-01,\n",
       "         -3.54262263e-01,  3.12517166e-01,  1.09546691e-01,\n",
       "         -3.27191681e-01, -2.35828027e-01,  1.72094703e-01,\n",
       "         -1.96366251e-01, -1.40337363e-01,  3.65347743e-01,\n",
       "          2.86626637e-01, -1.60023794e-01,  2.04558551e-01,\n",
       "         -3.34602892e-02, -2.78161347e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.02993375, -0.22956103,  0.06563419, ..., -0.12703282,\n",
       "          0.15335542, -0.11892658],\n",
       "        [ 0.18276739, -0.23352516,  0.19060421, ...,  0.12344128,\n",
       "          0.15017134, -0.18777084],\n",
       "        [ 0.10786277,  0.05524594, -0.07996106, ..., -0.13324201,\n",
       "         -0.22534394,  0.14554232],\n",
       "        ...,\n",
       "        [ 0.04161257,  0.245879  ,  0.11235863, ...,  0.04074568,\n",
       "         -0.15501618,  0.03642654],\n",
       "        [-0.11298418,  0.1806134 , -0.14270139, ...,  0.13310277,\n",
       "         -0.18859285, -0.04554921],\n",
       "        [ 0.05567873, -0.05678976,  0.043392  , ..., -0.18360299,\n",
       "          0.21738207, -0.13293046]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.09187399,  0.11321338, -0.12682652, ..., -0.03894466,\n",
       "          0.03758699,  0.05201039],\n",
       "        [-0.03345275, -0.13417436,  0.02808434, ...,  0.06227201,\n",
       "         -0.10567226,  0.05869479],\n",
       "        [ 0.06683938, -0.02543592, -0.08192281, ...,  0.14037497,\n",
       "          0.11261849,  0.03806926],\n",
       "        ...,\n",
       "        [-0.12382436, -0.08982399, -0.12089646, ..., -0.10681508,\n",
       "         -0.14550525, -0.05246157],\n",
       "        [-0.12788083, -0.02957718,  0.10190471, ...,  0.14473678,\n",
       "          0.06578967,  0.03034514],\n",
       "        [-0.11113711, -0.17118144,  0.1017618 , ...,  0.09214772,\n",
       "         -0.13331524, -0.1303283 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.11020374,  0.09273329,  0.05878705, ..., -0.11121488,\n",
       "         -0.04686636, -0.08755532],\n",
       "        [-0.056633  , -0.05486384,  0.03136554, ...,  0.07548171,\n",
       "          0.1044535 ,  0.00204664],\n",
       "        [-0.1088554 ,  0.07527503, -0.09123206, ...,  0.079292  ,\n",
       "          0.00108778, -0.0267494 ],\n",
       "        ...,\n",
       "        [-0.12285414, -0.02990049,  0.01757687, ..., -0.1192196 ,\n",
       "          0.11010671,  0.00584173],\n",
       "        [ 0.11574793,  0.10597286, -0.06078371, ...,  0.05715814,\n",
       "          0.09089863, -0.05777031],\n",
       "        [ 0.08731592,  0.1238513 ,  0.09553435, ..., -0.01738608,\n",
       "          0.049945  , -0.04590052]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[-1.30267948e-01],\n",
       "        [ 2.45010555e-02],\n",
       "        [-3.92383933e-02],\n",
       "        [-5.21253571e-02],\n",
       "        [-1.32325932e-01],\n",
       "        [ 4.80564386e-02],\n",
       "        [-4.65895459e-02],\n",
       "        [-3.44892368e-02],\n",
       "        [ 3.91519070e-02],\n",
       "        [-5.64619899e-02],\n",
       "        [ 3.87255847e-03],\n",
       "        [ 3.71068716e-04],\n",
       "        [ 1.49322763e-01],\n",
       "        [-4.93181944e-02],\n",
       "        [-6.95567429e-02],\n",
       "        [-6.60933554e-02],\n",
       "        [ 8.35282058e-02],\n",
       "        [ 2.44128555e-02],\n",
       "        [-3.33925709e-02],\n",
       "        [ 2.71931589e-02],\n",
       "        [-2.43735164e-02],\n",
       "        [ 3.09555382e-02],\n",
       "        [ 1.61676556e-02],\n",
       "        [ 5.06914258e-02],\n",
       "        [-1.50819972e-01],\n",
       "        [-1.46131516e-02],\n",
       "        [-3.91198918e-02],\n",
       "        [ 1.01432338e-01],\n",
       "        [-1.33201838e-01],\n",
       "        [ 1.30139008e-01],\n",
       "        [ 1.41429052e-01],\n",
       "        [ 1.44158468e-01],\n",
       "        [-1.96338892e-02],\n",
       "        [-1.20717496e-01],\n",
       "        [ 1.23068497e-01],\n",
       "        [ 8.92510414e-02],\n",
       "        [-7.18699619e-02],\n",
       "        [-9.32797790e-03],\n",
       "        [ 4.68017459e-02],\n",
       "        [ 1.22059509e-01],\n",
       "        [ 1.37724563e-01],\n",
       "        [ 8.13561827e-02],\n",
       "        [-5.52731752e-03],\n",
       "        [-1.14134893e-01],\n",
       "        [-4.20800522e-02],\n",
       "        [ 5.48703969e-03],\n",
       "        [-4.50855643e-02],\n",
       "        [ 6.19605333e-02],\n",
       "        [ 1.66368037e-02],\n",
       "        [ 2.34193951e-02],\n",
       "        [ 1.38907388e-01],\n",
       "        [-1.82183385e-02],\n",
       "        [ 8.49574953e-02],\n",
       "        [ 9.16058272e-02],\n",
       "        [ 1.50775388e-01],\n",
       "        [-1.00654393e-01],\n",
       "        [ 5.29086888e-02],\n",
       "        [-1.58217251e-02],\n",
       "        [ 1.36607781e-01],\n",
       "        [-1.26986951e-02],\n",
       "        [ 1.20599911e-01],\n",
       "        [-1.24352798e-01],\n",
       "        [ 1.51316449e-01],\n",
       "        [-1.44753963e-01],\n",
       "        [ 7.64144659e-02],\n",
       "        [ 2.09799856e-02],\n",
       "        [ 1.16004184e-01],\n",
       "        [-9.77518559e-02],\n",
       "        [ 8.04077238e-02],\n",
       "        [-1.48171201e-01],\n",
       "        [ 7.44625926e-02],\n",
       "        [ 1.09304205e-01],\n",
       "        [ 5.29433042e-02],\n",
       "        [-1.27408907e-01],\n",
       "        [ 3.57747078e-02],\n",
       "        [-7.95330927e-02],\n",
       "        [-8.94464105e-02],\n",
       "        [-1.13123544e-01],\n",
       "        [-4.79918122e-02],\n",
       "        [-3.67627069e-02],\n",
       "        [ 5.76646328e-02],\n",
       "        [-1.30186707e-01],\n",
       "        [-1.01233646e-01],\n",
       "        [-8.23131055e-02],\n",
       "        [ 5.64549565e-02],\n",
       "        [ 2.18941420e-02],\n",
       "        [ 5.16809970e-02],\n",
       "        [ 3.20151895e-02],\n",
       "        [ 1.33003578e-01],\n",
       "        [-1.05871044e-01],\n",
       "        [-1.39256909e-01],\n",
       "        [-2.45826840e-02],\n",
       "        [ 4.72406447e-02],\n",
       "        [-1.23261705e-01],\n",
       "        [ 7.77175725e-02],\n",
       "        [ 1.05230764e-01],\n",
       "        [-1.23647779e-01],\n",
       "        [ 1.40687898e-01],\n",
       "        [ 3.06991488e-02],\n",
       "        [ 1.39074847e-01],\n",
       "        [ 1.38826475e-01],\n",
       "        [-9.82617959e-02],\n",
       "        [-1.47745997e-01],\n",
       "        [ 5.49625009e-02],\n",
       "        [-1.40697569e-01],\n",
       "        [ 3.88060212e-02],\n",
       "        [-1.63360387e-02],\n",
       "        [-1.49065822e-01],\n",
       "        [-8.03066641e-02],\n",
       "        [-7.25282729e-02],\n",
       "        [ 1.51278928e-01],\n",
       "        [ 6.50194883e-02],\n",
       "        [-1.51871741e-01],\n",
       "        [-1.74015164e-02],\n",
       "        [ 1.24747500e-01],\n",
       "        [ 8.91750157e-02],\n",
       "        [ 9.20079648e-03],\n",
       "        [-1.05791338e-01],\n",
       "        [-1.89204663e-02],\n",
       "        [-1.13809794e-01],\n",
       "        [-3.09483707e-03],\n",
       "        [ 9.18766409e-02],\n",
       "        [ 1.47816464e-01],\n",
       "        [ 1.15194395e-01],\n",
       "        [-3.62171456e-02],\n",
       "        [ 3.56896818e-02],\n",
       "        [-7.25323856e-02],\n",
       "        [-1.25414133e-03],\n",
       "        [-1.16483271e-02],\n",
       "        [ 1.74730718e-02],\n",
       "        [-1.18113466e-01],\n",
       "        [-8.68398324e-02],\n",
       "        [ 2.83743143e-02],\n",
       "        [-4.71163839e-02],\n",
       "        [-8.07157159e-03],\n",
       "        [-8.91588032e-02],\n",
       "        [ 2.48752534e-03],\n",
       "        [ 1.45378456e-01],\n",
       "        [-7.01305270e-03],\n",
       "        [ 1.63287222e-02],\n",
       "        [-1.03278786e-01],\n",
       "        [-6.14226609e-02],\n",
       "        [-3.35825980e-03],\n",
       "        [-4.79666889e-03],\n",
       "        [-1.26211375e-01],\n",
       "        [-1.48424998e-01],\n",
       "        [ 1.87204033e-02],\n",
       "        [ 5.98901659e-02],\n",
       "        [-4.59060222e-02],\n",
       "        [ 1.24269411e-01],\n",
       "        [ 6.34816438e-02],\n",
       "        [ 9.20005292e-02],\n",
       "        [ 1.06063798e-01],\n",
       "        [ 1.19024530e-01],\n",
       "        [-1.42083421e-01],\n",
       "        [-3.56206894e-02],\n",
       "        [ 1.43468991e-01],\n",
       "        [ 8.33977461e-02],\n",
       "        [-1.34832561e-01],\n",
       "        [ 5.05692512e-02],\n",
       "        [-2.70578712e-02],\n",
       "        [ 1.16518572e-01],\n",
       "        [ 1.47255525e-01],\n",
       "        [-1.17748700e-01],\n",
       "        [ 1.25672653e-01],\n",
       "        [-3.97894233e-02],\n",
       "        [ 1.23332188e-01],\n",
       "        [-1.18461221e-01],\n",
       "        [-4.10735831e-02],\n",
       "        [-1.91876739e-02],\n",
       "        [-1.04710773e-01],\n",
       "        [-2.57417262e-02],\n",
       "        [-4.73581254e-02],\n",
       "        [ 4.27672863e-02],\n",
       "        [ 3.75934690e-02],\n",
       "        [ 6.28823340e-02],\n",
       "        [ 1.02728114e-01],\n",
       "        [-4.78383750e-02],\n",
       "        [ 2.35234350e-02],\n",
       "        [-9.97184515e-02],\n",
       "        [ 7.01395720e-02],\n",
       "        [ 1.28306136e-01],\n",
       "        [ 1.31757870e-01],\n",
       "        [ 9.29951221e-02],\n",
       "        [ 1.09215155e-01],\n",
       "        [ 1.33038163e-02],\n",
       "        [-3.32375616e-02],\n",
       "        [-1.04138620e-01],\n",
       "        [ 9.40513909e-02],\n",
       "        [ 1.38201371e-01],\n",
       "        [-6.81798682e-02],\n",
       "        [ 4.60616201e-02],\n",
       "        [ 2.02837586e-03],\n",
       "        [ 1.64936483e-03],\n",
       "        [-6.68294728e-02],\n",
       "        [-1.09590717e-01],\n",
       "        [ 1.42733887e-01],\n",
       "        [-1.14526972e-01],\n",
       "        [ 1.10752329e-01],\n",
       "        [-1.30895734e-01],\n",
       "        [ 1.21315226e-01],\n",
       "        [-5.39332628e-02],\n",
       "        [-1.14649191e-01],\n",
       "        [-1.85216814e-02],\n",
       "        [ 1.17553756e-01],\n",
       "        [-5.75200394e-02],\n",
       "        [-2.72635818e-02],\n",
       "        [-1.39097750e-01],\n",
       "        [ 6.58502579e-02],\n",
       "        [-1.30315408e-01],\n",
       "        [-9.15410519e-02],\n",
       "        [ 1.08652696e-01],\n",
       "        [-8.08378756e-02],\n",
       "        [ 4.39847112e-02],\n",
       "        [ 9.02396590e-02],\n",
       "        [ 1.31736174e-01],\n",
       "        [-8.01351890e-02],\n",
       "        [ 7.86587894e-02],\n",
       "        [ 4.31484878e-02],\n",
       "        [ 7.31968582e-02],\n",
       "        [ 8.08573961e-02],\n",
       "        [-4.18722630e-06],\n",
       "        [-1.00190900e-01],\n",
       "        [ 7.89037794e-02],\n",
       "        [-3.74479741e-02],\n",
       "        [-2.24582553e-02],\n",
       "        [ 5.66557050e-03],\n",
       "        [-3.35778296e-03],\n",
       "        [-5.27022108e-02],\n",
       "        [-1.25334486e-01],\n",
       "        [-1.14291131e-01],\n",
       "        [-1.35340124e-01],\n",
       "        [ 2.04188675e-02],\n",
       "        [-2.48214453e-02],\n",
       "        [ 8.21429789e-02],\n",
       "        [ 7.52339065e-02],\n",
       "        [ 9.07534957e-02],\n",
       "        [ 5.91576099e-04],\n",
       "        [ 3.53673100e-03],\n",
       "        [ 2.86628306e-03],\n",
       "        [ 1.49670258e-01],\n",
       "        [ 8.58119875e-02],\n",
       "        [-7.95035064e-02],\n",
       "        [ 1.04331836e-01],\n",
       "        [-1.66713297e-02],\n",
       "        [ 1.51233688e-01],\n",
       "        [-1.28907278e-01],\n",
       "        [ 1.15694746e-01],\n",
       "        [-2.34758258e-02],\n",
       "        [ 1.31763533e-01],\n",
       "        [ 1.22481436e-02],\n",
       "        [ 2.63675749e-02],\n",
       "        [ 7.31657147e-02],\n",
       "        [-1.61248147e-02],\n",
       "        [ 1.29778698e-01],\n",
       "        [-1.49920523e-01]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "462720/462720 [==============================] - 12s 25us/step - loss: 0.4820 - accuracy: 0.7502\n",
      "Epoch 2/15\n",
      "462720/462720 [==============================] - 12s 26us/step - loss: 0.4814 - accuracy: 0.7505\n",
      "Epoch 3/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4806 - accuracy: 0.7514\n",
      "Epoch 4/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4796 - accuracy: 0.7524\n",
      "Epoch 5/15\n",
      "462720/462720 [==============================] - 13s 27us/step - loss: 0.4787 - accuracy: 0.7524\n",
      "Epoch 6/15\n",
      "462720/462720 [==============================] - 12s 26us/step - loss: 0.4781 - accuracy: 0.7529\n",
      "Epoch 7/15\n",
      "462720/462720 [==============================] - 12s 26us/step - loss: 0.4776 - accuracy: 0.7534\n",
      "Epoch 8/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4771 - accuracy: 0.7533\n",
      "Epoch 9/15\n",
      "462720/462720 [==============================] - 13s 29us/step - loss: 0.4768 - accuracy: 0.7538\n",
      "Epoch 10/15\n",
      "462720/462720 [==============================] - 13s 29us/step - loss: 0.4760 - accuracy: 0.7546\n",
      "Epoch 11/15\n",
      "462720/462720 [==============================] - 14s 30us/step - loss: 0.4753 - accuracy: 0.7551\n",
      "Epoch 12/15\n",
      "462720/462720 [==============================] - 13s 28us/step - loss: 0.4750 - accuracy: 0.7556\n",
      "Epoch 13/15\n",
      "462720/462720 [==============================] - 14s 29us/step - loss: 0.4742 - accuracy: 0.7556\n",
      "Epoch 14/15\n",
      "462720/462720 [==============================] - 14s 30us/step - loss: 0.4743 - accuracy: 0.7558\n",
      "Epoch 15/15\n",
      "462720/462720 [==============================] - 13s 27us/step - loss: 0.4742 - accuracy: 0.7561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f454a95a58>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train3, y_train3, epochs=15, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model.predict(X_test3)\n",
    "y_pred3\n",
    "rounded2 = [round(x[0]) for x in y_pred3]\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test3, rounded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy \n",
    "accuracy_score(y_test3, rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMITYR\n",
    "RELEASEYR\n",
    "MAND_PRISREL_YEAR\n",
    "PROJ_PRISREL_YEAR\n",
    "PARELIG_YEAR\n",
    "OFFDETAIL\n",
    "TIMESRVD\n",
    "STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3\n",
    "\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/decision-tree-classification-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
